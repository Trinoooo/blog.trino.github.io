[{"title":"新的开始","path":"/新的开始/","content":"做点自己喜欢的事情吧 2022 年 7 月 27 日","tags":["开端"]},{"title":"关于","path":"/about/index.html","content":"悟已往之不谏，知来者之可追。实迷途其未远，觉今是而昨非"},{"path":"/wiki/computer-network/index.html","content":"请注意：本资源来源于网络，如有侵权请联系删除"},{"title":"写在前面","path":"/wiki/computer-systems:a-programmer's-perspective/chapter_01.html","content":"计算机系统是由硬件和系统软件组成的，它们共同工作来运行应用程序。虽然系统的具体实现方式随着时间不断变化，但是系统内在的概念却没有改变。所有计算机系统都有相似的硬件和软件组件，它们又执行着相似的功能。一些程序员希望深入了解这些组件是如何工作的以及这些组件是如何影响程序的正确性和性能的，以此来提高自身的技能。本书便是为这些读者而写的。现在就要开始一次有趣的漫游历程了。如果你全力投身学习本书中的概念，完全理解底层计算机系统以及它对应用程序的影响，那么你会步上成为为数不多的“大牛”的道路。你将会学习一些实践技巧，比如如何避免由计算机表示数字的方式引起的奇怪的数字错误。你将学会怎样通过一些小窍门来优化自己的 C 代码，以充分利用现代处理器和存储器系统的设计。你将了解编译器是如何实现过程调用的，以及如何利用这些知识来避免缓冲区溢出错误带来的安全漏洞，这些弱点给网络和因特网软件带来了巨大的麻烦。你将学会如何识别和避免链接时那些令人讨厌的错误，它们困扰着普通的程序员。你将学会如何编写自己的 Unix shell、自己的动态存储分配包，甚至于自己的 Web 服务器。你会认识并发带来的希望和陷阱，这个主题随着单个芯片上集成了多个处理器核变得越来越重要。在 Kernighan 和 Ritchie 的关于 C 编程语言的经典教材中，他们通过图 1-1 中所示的 hello 程序来向读者介绍 C。尽管 hello 程序非常简单，但是为了让它实现运行，系统的每个主要组成部分都需要协调工作。从某种意义上来说，本书的目的就是要帮助你了解当你在系统上执行 hello 程序时，系统发生了什么以及为什么会这样。 123456#include &lt;stdio.h&gt;int main()&#123; printf(&quot;hello, world &quot;); return 0;&#125; 图1-1指上面代码块，代码文件路径code&#x2F;intro&#x2F;hello.c 我们通过跟踪 hello 程序的生命周期来开始对系统的学习——从它被程序员创建开始，到在系统上运行，输出简单的消息，然后终止。我们将沿着这个程序的生命周期，简要地介绍一些逐步出现的关键概念、专业术语和组成部分。后面的章节将围绕这些内容展开。"},{"title":"前言","path":"/wiki/computer-systems:a-programmer's-perspective/index.html","content":"请注意：本资源来源于网络，如有侵权请联系删除 本书（简称 CS：APP）的主要读者是计算机科学家、计算机工程师，以及那些想通过学习计算机系统的内在运作而能够写出更好程序的人。我们的目的是解释所有计算机系统的本质概念，并向你展示这些概念是如何实实在在地影响应用程序的正确性、性能和实用性的。其他的系统类书籍都是从构建者的角度来写的，讲述如何实现硬件或系统软件，包括操作系统、编译器和网络接口。而本书是从程序员的角度来写的，讲述应用程序员如何能够利用系统知识来编写出更好的程序。当然，学习一个计算机系统应该做些什么，是学习如何构建一个计算机系统的很好的出发点，所以，对于希望继续学习系统软硬件实现的人来说，本书也是一本很有价值的介绍性读物。大多数系统书籍还倾向于重点关注系统的某一个方面，比如：硬件架构、操作系统、编译器或者网络。本书则以程序员的视角统一覆盖了上述所有方面的内容。如果你研究和领会了这本书里的概念，你将开始成为极少数的”牛人”，这些”牛人”知道事情是如何运作的，也知道当事情出现故障时如何修复。你写的程序将能够更好地利用操作系统和系统软件提供的功能，对各种操作条件和运行时参数都能正确操作，运行起来更快，并能避免出现使程序容易受到网络攻击的缺陷。同时，你也要做好更深入探究的准备，研究像编译器、计算机体系结构、操作系统、嵌入式系统、网络互联和网络安全这样的高级题目。 读者应具备的背景知识本书的重点是执行 x86-64 机器代码的系统。对英特尔及其竞争对手而言，x86-64 是他们自 1978 年起，以8086 微处理器为代表，不断进化的最新成果。按照英特尔微处理器产品线的命名规则，这类微处理器俗称为 “x86”。随着半导体技术的演进，单芯片上集成了更多的晶体管，这些处理器的计算能力和内存容量有了很大的增长。在这个过程中，它们从处理 16 位字，发展到引人 IA32 处理器处理 32 位字，再到最近的 x86-64 处理 64 位字。我们考虑的是这些机器如何在 Linux 操作系统上运行 C 语言程序。Linux 是众多继承自最初由贝尔实验室开发的 Unix 的操作系统中的一种。这类操作系统的其他成员包括 Solaris、FreeBSD 和 Mac OSX。近年来，由于 Posix 和标准 Unix 规范的标准化努力，这些操作系统保持了高度兼容性。因此，本书内容几乎直接适用于这些“类 Unix”操作系统。文中包含大量已在 Linux 系统上编译和运行过的程序示例。我们假设你能访问一台这样的机器，并且能够登录，做一些诸如切换目录之类的简单操作。如果你的计算机运行的是 Microsoft Windows 系统，我们建议你选择安装一个虚拟机环境（例如 VirtualBox 或者 VMWare），以便为一种操作系统（客户 OS）编写的程序能在另一种系统（宿主 OS）上运行。我们还假设你对 C 和 C++ 有一定的了解。如果你以前只有 Java 经验，那么你需要付出更多的努力来完成这种转换，不过我们也会帮助你。Java 和 C 有相似的语法和控制语句。不过，有一些 C 语言的特性（特别是指针、显式的动态内存分配和格式化 I&#x2F;O）在 Java 中都是没有的。所幸的是，C 是一个较小的语言，在Brian Kernighan和Dennis Ritchie经典的”K8.R”文献中得到了清晰优美的描述【61】。无论你的编程背景如何，都应该考虑将 K&amp;R 作为个人系统藏书的一部分。如果你只有使用解释性语言的经验，如 Python、Ruby 或 Perl，那么在使用本书之前，需要花费一些时间来学习 C。本书的前几章揭示了C语言程序和它们相对应的机器语言程序之间的交互作用。机器语言示例都是用运行在 x86-64 处理器上的 GNUGCC 编译器生成的。我们不需要你以前有任何硬件、机器语言或是汇编语言编程的经验。 给C语言初学者 - 关于C编程语言的建议为了帮助C语言编程背景薄弱（或全无背景）的读者，我们在书中加入了这样一些专门的注释来突出 C 中一些特别重要的特性。我们假设你熟悉 C++ 或 Java。 如何阅读此书从程序员的角度学习计算机系统是如何工作的会非常有趣，主要是因为你可以主动地做这件事情。无论何时你学到一些新的东西，都可以马上试验并且直接看到运行结果。事实上，我们相信学习系统的唯一方法就是做（do）系统，即在真正的系统上解决具体的问题，或是编写和运行程序。这个主题观念贯穿全书。当引入一个新概念时，将会有一个或多个练习题紧随其后，你应该马上做一做来检验你的理解。这些练习题的解答在每章的末尾。当你阅读时，尝试自己来解答每个问题，然后再查阅答案，看自已的答案是否正确。除第 1 章外，每章后面都有难度不同的家庭作业。对每个家庭作业题，我们标注了难度级别： ① 只需要几分钟。几乎或完全不需要编程。 ② 可能需要将近 20 分钟。通常包括编写和测试一些代码。（许多都源自我们在考试中出的题目。） ③ 需要很大的努力，也许是 1～2 个小时。一般包括编写和测试大量的代码。 ④ 一个实验作业，需要将近 10 个小时。 文中每段代码示例都是由经过 GCC 编译的 C 程序直接生成并在 Linux 系统上进行了测试，没有任何人为的改动。当然，你的系统上 GCC 的版本可能不同，或者根本就是另外一种编译器，那么可能生成不一样的机器代码，但是整体行为表现应该是一样的。所有的源程序代码都可以从 csapp.cs.cmu.edu 上 的CS：APP 主页上获取。在本书中，源程序的文件名列在两条水平线的右边，水平线之间是格式化的代码。比如，图1中的程序能在 code&#x2F;intro&#x2F; 目录下的 hello.c 文件中找到。当遇到这些示例程序时，我们鼓励你在自己的系统上试着运行它们。为了避免本书体积过大、内容过多，我们添加了许多网络旁注（Web aside），包括一些对本书主要内容的补充资料。本书中用 CHAP：TOP 这样的标记形式来引用这些旁注，这里 CHAP 是该章主题的缩写编码，而 TOP 是涉及的话题的缩写编码。例如，网络旁注 DATA：BOOL 包含对第 2 章中数据表示里面有关布尔代数内容的补充资料；而网络旁注 ARCH：VLOG 包含的是用 Verilog 硬件描述语言进行处理器设计的资料，是对第 4 章中处理器设计部分的补充。所有的网络旁注都可以从 CS：APP 的主页上获取。 旁注-什么是旁注在整本书中，你将会遇到很多以这种形式出现的旁注。旁注是附加说明，能使你对当前讨论的主题多一些了解。旁注可以有很多用处。一些是小的历史故事。例如，C 语言、Linux 和 Internet 是从何而来的？有些旁注则是用来澄清学生们经常感到疑感的问题。例如，高速缓存的行、组和块有什么区别？还有些旁注给出了一些现实世界的例子。例如，一个浮点错误怎么毁掉了法国的一枚火箭，或是给出市面上出售的一个磁盘驱动器的几何和运行参数。最后，还有一些旁注仅仅就是一些有趣的内容，例如，什么是“hoinky”？ 本书概述本书由 12 章组成，旨在阐述计算机系统的核心概念。内容概述如下： 第1章：计算机系统漫游。 这一章通过研究 “hello, world” 这个简单程序的生命周期，介绍计算机系统的主要概念和主题。 第2章：信息的表示和处理。 我们讲述了计算机的算术运算，重点描述了会对程序员有 影响的无符号数和数的补码表示的特性。我们考虑数字是如何表示的，以及由此确定对于一个给定的字长，其可能编码值的范围。我们探讨有符号和无符号数字之间类型转换的效果，还阐述算术运算的数学特性。菜鸟级程序员经常很惊奇地了解到（用补码表示的）两个正数的和或者积可能为负。另一方面，补码的算术运算满足很多整数运算的代数特性，因此，编译器可以很安全地把一个常量乘法转化为一系列的移位和加法。我们用C 语言的位级操作来说明布尔代数的原理和应用。我们从两个方面讲述了 IEEE 标准的浮点格式：一是如何用它来表示数值，一是浮点运算的数学属性。对计算机的算术运算有深刻的理解是写出可靠程序的关键。比如，程序员和编译器不能用表达式（x-y&lt;0）来替代（x&lt;y），因为前者可能会产生溢出。甚至也不能用表达式（-y&lt;-x）来替代，因为在补码表示中负数和正数的范围是不对称的。算术溢出是造成程序错误和安全漏洞的一个常见根源，然而很少有书从程序员的角度来讲述计算机算术运算的特性。 第3章：程序的机器级表示。 我们教读者如何阅读由 C 编译器生成的 x86-64 机器代码。我们说明为不同控制结构（比如条件、循环和开关语句）生成的基本指令模式。我们还讲述过程的实现，包括栈分配、寄存器使用惯例和参数传递。我们讨论不同数据结构（如结构、联合和数组）的分配和访问方式。我们还说明实现整数和浮点数算术运算的指令。我们还以分析程序在机器级的样子作为途径，来理解常见的代码安全漏洞（例如缓冲区溢出），以及理解程序员、编译器和操作系统可以采取的减轻这些威胁的措施。学习本章的概念能够帮助读者成为更好的程序员，因为你们懂得程序在机器上是如何表示的。另外一个好处就在于读者会对指针有非常全面而具体的理解。 第4章：处理器体系结构。 这一章讲述基本的组合和时序逻辑元素，并展示这些元素如何在数据通路中组合到一起，来执行 x86-64 指令集的一个称为 “Y86-64” 的简化子集。我们从设计单时钟周期数据通路开始。这个设计概念上非常简单，但是运行速度不会太快。然后我们引入流水线的思想，将处理一条指令所需要的不同步骤实现为独立的阶段。这个设计中，在任何时刻，每个阶段都可以处理不同的指令。我们的五阶段处理器流水线更加实用。本章中处理器设计的控制逻辑是用一种称为 HCL 的简单硬件描述语言来描述的。用 HCL 写的硬件设计能够编译和链接到本书提供的模拟器中，还可以根据这些设计生成 Verilog 描述，它适合合成到实际可以运行的硬件上去。 第5章：优化程序性能。 在这一章里，我们介绍了许多提高代码性能的技术，主要思想就是让程序员通过使编译器能够生成更有效的机器代码来学习编写 C 代码。我们一开始介绍的是减少程序需要做的工作的变换，这些是在任何机器上写任何程序时都应该遵循的。然后讲的是增加生成的机器代码中指令级并行度的变换，因而提高了程序在现代“超标量”处理器上的性能。为了解释这些变换行之有效的原理，我们介绍了一个简单的操作模型，它描述了现代乱序处理器是如何工作的，然后给出了如何根据一个程序的图形化表示中的关键路径来测量一个程序可能的性能。你会惊讶于对 C 代码做一些简单的变换能给程序带来多大的速度提升。 第6章：存储器层次结构。 对应用程序员来说，存储器系统是计算机系统中最直接可见的部分之一。到目前为止，读者一直认同这样一个存储器系统概念模型，认为它是一个有一致访问时间的线性数组。实际上，存储器系统是一个由不同容量、造价和访问时间的存储设备组成的层次结构。我们讲述不同类型的随机存取存储器（RAM）和只读存储器（ROM），以及磁盘和✦固态硬盘✦的几何形状和组织构造。我们描述这些存储设备是如何放置在层次结构中的，讲述访问局部性是如何使这种层次结构成为可能的。我们通过一个独特的观点使这些理论具体化，那就是将存储器系统视为一个“存储器山”，山脊是时间局部性，而斜坡是空间局部性。最后，我们向读者阐述如何通过改善程序的时间局部性和空间局部性来提高应用程序的性能。固态硬盘：直译应为固态驱动器，但固态硬盘一词已经被大家接受，所以沿用。——译者注 第7章：链接。 本章讲述静态和动态链接，包括的概念有可重定位的和可执行的目标文件、符号解析、重定位、静态库、共享目标库、位置无关代码，以及库打桩。大多数讲述系统的书中都不讲链接，我们要讲述它是出于以下原因。第一，程序员遇到的最令人迷惑的问题中，有一些和链接时的小故障有关，尤其是对那些大型软件包来说。第二，链接器生成的目标文件是与一些像加载、虚拟内存和内存映射这样的概念相关的。 第8章：异常控制流。 在本书的这个部分，我们通过介绍异常控制流（即除正常分支和过程调用以外的控制流的变化）的一般概念，打破单一程序的模型。我们给出存在于系统所有层次的异常控制流的例子，从底层的硬件异常和中断，到并发进程的上下文切换，到由于接收 Linux 信号引起的控制流突变，到 C 语言中破坏栈原则的非本地跳转。 在这一章，我们介绍进程的基本概念，进程是对一个正在执行的程序的一种抽象。读者会学习进程是如何工作的，以及如何在应用程序中创建和操纵进程。我们会展示应用程序员如何通过 Linux 系统调用来使用多个进程。学完本章之后，读者就能够编写带作业控制的 Linux shell 了。同时，这里也会向读者初步展示程序的并发执行会引起不确定的行为。 第9章：虚拟内存。我们讲述虚拟内存系统是希望读者对它是如何工作的以及它的特性有所了解。我们想让读者了解为什么不同的并发进程各自都有一个完全相同的地址范围，能共享某些页，而又独占另外一些页。我们还讲了一些管理和操纵虚拟内存的问题。特别地，我们讨论了存储分配操作，就像标准库的 malloc 和 free 操作。阐述这些内容是出于下面几个目的。它加强了这样一个概念，那就是虚拟内存空间只是一个字节数组，程序可以把它划分成不同的存储单元。它可以帮助读者理解当程序包含存储泄漏和非法指针引用等内存引用错误时的后果。最后，许多应用程序员编写自己的优化了的存储分配操作来满足应用程序的需要和特性。这一章比其他任何一章都更能展现将计算机系统中的硬件和软件结合起来阐述的优点。而传统的计算机体系结构和操作系统书籍都只讲述虚拟内存的某一方面。 第10章：系统级 I&#x2F;O。 我们讲述 Unix I&#x2F;O 的基本概念，例如文件和描述符。我们描述如何共享文件，I&#x2F;O 重定向是如何工作的，还有如何访问文件的元数据。我们还开发了一个健壮的带缓冲区的 I&#x2F;O 包，可以正确处理一种称为 short counts 的奇特行为，也就是库函数只读取一部分的输入数据。我们阐述 C 的标准 I&#x2F;O 库，以及它与 Linux I&#x2F;O 的关系，重点谈到标准 I&#x2F;O 的局限性，这些局限性使之不适合网络编程。总的来说，本章的主题是后面两章——网络和并发编程的基础。 第11章：网络编程。 对编程而言，网络是非常有趣的 I&#x2F;O 设备，它将许多我们前面文中学习的概念（比如进程、信号、字节顺序、内存映射和动态内存分配）联系在一起。网络程序还为下一章的主题——并发，提供了一个很令人信服的上下文。本章只是网络编程的一个很小的部分，使读者能够编写一个简单的 Web 服务器。我们还讲述位于所有网络程序底层的客户端-服务器模型。我们展现了一个程序员对 Internet 的观点，并且教读者如何用套接字接口来编写 Internet 客户端和服务器。最后，我们介绍超文本传输协议（HTTP），并开发了一个简单的迭代式 Web 服务器。 第12章：并发编程。 这一章以 Internet 服务器设计为例介绍了并发编程。我们比较对照了三种编写并发程序的基本机制（进程、I&#x2F;O多路复用和线程），并且展示如何用它们来建造并发Internet服务器。我们探讨了用 P、V 信号量操作来实现同步、线程安全和可重入、竞争条件以及死锁等的基本原则。对大多数服务器应用来说，写并发代码都是很关键的。我们还讲述了线程级编程的使用方法，用这种方法来表达应用程序中的并行性，使得程序在多核处理器上能执行得更快。使用所有的核解决同一个计算问题需要很小心谨慎地协调并发线程，既要保证正确性，又要争取获得高性能。 本版新增内容本书的第 1 版于 2003 年出版，第 2 版在 2011 年出版。考虑到计算机技术发展如此迅速，这本书的内容还算是保持得很好。事实证明 Intel x86 的机器上运行 Linux （以及相关操作系统），加上采用 C 语言编程，是一种能够涵盖当今许多系统的组合。然而，硬件技术、编译器和程序库接口的变化，以及很多教师教授这些内容的经验，都促使我们做了大量的修改。第 2 版以来的最大整体变化是，我们的介绍从以 IA32 和 x86-64 为基础，转变为完全以 x86-64 为基础。这种重心的转移影响了很多章节的内容。下面列出一些明显的变化∶ 第1章。我们将第 5 章对 Amdahl 定理的讨论移到了本章。 第2章。读者和评论家的反馈是一致的，本章的一些内容有点令人不知所措。因此，我们澄清了一些知识点，用更加数学的方式来描述，使得这些内容更容易理解。这使得读者能先略过数学细节，获得高层次的总体概念，然后回过头来进行更细致深入的阅读。 第3章。我们将之前基于 IA32 和 x86-64 的表现形式转换为完全基于 x86-64 ，还更新了近期版本 GCC 产生的代码。其结果是大量的重写工作，包括修改了一些概念提出的顺序。同时，我们还首次介绍了对处理浮点数据的程序的机器级支持。由于历史原因，我们给出了一个网络旁注描述 IA32 机器码。 第4章。我们将之前基于 32 位架构的处理器设计修改为支持 64 位字和操作的设计。 第5章。我们更新了内容以反映最近几代 x86-64 处理器的性能。通过引入更多的功能单元和更复杂的控制逻辑，我们开发的基于程序数据流表示的程序性能模型，其性能预测变得 比之前更加可靠。 第6章。我们对内容进行了更新，以反映更多的近期技术。 第7章。针对 x86-64，我们重写了本章，扩充了关于用 GOT 和 PLT 创建位置无关代码的讨论，新增了一节描述更加强大的链接技术，比如库打桩。 第8章。我们增加了对信号处理程序更细致的描述，包括异步信号安全的函数，编写信号处理程序的具体指导原则，以及用 sigsuspend 等待处理程序。 第9章。本章变化不大。 第10章。我们新增了一节说明文件和文件的层次结构，除此之外，本章的变化 不大。 第11章。我们介绍了采用最新 getaddrinfo 和 getnameinfo 函数的、与协议无关和线程安全的网络编程，取代过时的、不可重入的 gethostbyname 和 gethost-byaddr 函数。 第12章。我们扩充了利用线程级并行性使得程序在多核机器上更快运行的内容。 此外，我们还增加和修改了很多练习题和家庭作业。 本书的起源本书起源于 1998 年秋季，我们在卡内基-梅隆（CMU）大学开设的一门编号为 15-213 的介绍性课程∶计算机系统导论（Introduction to Computer System，ICS）【14】。从那以后，每学期都开设了 ICS 这门课程，每学期有超过 400 名学生上课，这些学生从本科二年级到硕士研究生都有，所学专业也很广泛。这门课程是卡内基-梅隆大学计算机科学系（CS）以及电子和计算机工程系（ECE）所有本科生的必修课，也是 CS 和 ECE 大多数高级系统课程的先行必修课。ICS 这门课程的宗旨是用一种不同的方式向学生介绍计算机。因为，我们的学生中几乎没有人有机会亲自去构造一个计算机系统。另一方面，大多数学生，甚至包括所有的计算机科学家和计算机工程师，也需要日常使用计算机和编写计算机程序。所以我们决定从程序员的角度来讲解系统，并采用这样的原则过滤要讲述的内容∶我们只讨论那些影响用户级 C 语言程序的性能、正确性或实用性的主题。比如，我们排除了诸如硬件加法器和总线设计这样的主题。虽然我们谈及了机器语言，但是重点并不在于如何手工编写汇编语言，而是关注 C 语言编译器是如何将 C 语言的结构翻译成机器代码的，包括编译器是如何翻译指针、循环、过程调用以及开关（switch）语句的。更进一步地，我们将更广泛和全盘地看待系统，包括硬件和系统软件，涵盖了包括链接、加载、进程、信号、性能优化、虚拟内存、I&#x2F;O 以及网络与并发编程等在内的主题。这种做法使得我们讲授 ICS 课程的方式对学生来讲既实用、具体，还能动手操作，同时也非常能调动学生的积极性。很快地，我们收到来自学生和教职工非常热烈而积极的反响，我们意识到卡内基-梅隆大学以外的其他人也可以从我们的方法中获益。因此，这本书从 ICS 课程的笔记中应运而生了，而现在我们对它做了修改，使之能够反映科学技术以及计算机系统实现中的变化和进步。通过本书的多个版本和多种语言译本， ICS 和许多相似课程已经成为世界范围内数百所高校的计算机科学和计算机工程课程的一部分。 写给指导教师们∶可以基于本书的课程指导教师可以使用本书来讲授五种不同类型的系统课程。具体每门课程则有赖于课程大纲的要求、个人喜好、学生的背景和能力。图中的课程从左往右越来越强调以程序员的角度来看待系统。以下是简单的描述。 ORG：一门以非传统风格讲述传统主题的计算机组成原理课程。传统的主题包括逻辑设计、处理器体系结构、汇编语言和存储器系统，然而这里更多地强调了对程序员的影响。例如，要反过来考虑数据表示对 C 语言程序的数据类型和操作的影响。又例如，对汇编代码的讲解是基于C语言编译器产生的机器代码，而不是手工编写的汇编代码。 ORG+：一门特别强调硬件对应用程序性能影响的 ORG 课程。和 ORG 课程相比，学生要更多地学习代码优化和改进 C 语言程序的内存性能。 ICS：基本的ICS课程，旨在培养一类程序员，他们能够理解硬件、操作系统和编译系统对应用程序的性能和正确性的影响。和 ORG+ 课程的一个显著不同是，本课程不涉及低层次的处理器体系结构。相反，程序员只同现代乱序处理器的高级模型打交道。ICS 课程非常适合安排到一个 10 周的小学期，如果期望步调更从容一些，也可以延长到一个 15 周的学期。 ICS+：在基本的 ICS 课程基础上，额外论述一些系统编程的问题，比如系统级 I&#x2F;O、网络编程和并发编程。这是卡内基-梅隆大学的一门一学期时长的课程，会讲述本书中除了低级处理器体系结构以外的所有章。 SP：一门系统编程课程。和 ICS+ 课程相似，但是剔除了浮点和性能优化的内容，更加强调系统编程，包括进程控制、动态链接、系统级I&#x2F;O、网络编程和并发编程。指导教师可能会想从其他渠道对某些高级主题做些补充，比如守护进程（daemon）、终端控制和 Unix IPC（进程间通信）。 如果你希望学生更多地了解低层次的处理器体系结构，那么通过 ORG 和 ORG+ 课程可以达到目的。另一方面，如果你想将当前的计算机组成原理课程转换成 ICS 或者 ICS+ 课程，但是又对突然做这样剧烈的变化感到担心，那么你可以逐步递增转向 ICS 课程。你可以从 OGR 课程开始，它以一种非传统的方式教授传统的问题。一旦你对这些内容感到驾轻就熟了，就可以转到 ORG+，最终转到 ICS。如果学生没有 C 语言的经验（比如他们只用 Java 编写过程序），你可以花几周的时间在 C 语言上，然后再讲述 ORG 或者 ICS 课程的内容。最后，我们认为 ORG+ 和 SP 课程适合安排为两期（两个小学期或者两个学期）。或者你可以考虑按照一期 ICS 和一期 SP 的方式来教授 ICS+ 课程。 写给指导教师们∶经过课堂验证的实验练习ICS+ 课程在卡内基-梅隆大学得到了学生很高的评价。学生对这门课程的评价，中值分数一般为 5.0&#x2F;5.0，平均分数一般为 4.6&#x2F;5.0。学生们说这门课非常有趣，令人兴奋，主要就是因为相关的实验练习。这些实验练习可以从 CS∶APP 的主页上获得。下面是本书提供的一些实验的示例。 数据实验。这个实验要求学生实现简单的逻辑和算术运算函数，但是只能使用一个非常有限的C语言子集。比如，只能用位级操作来计算一个数字的绝对值。这个实验可帮助学生了解C语言数据类型的位级表示，以及数据操作的位级行为。 二进制炸弹实验。二进制炸弹是一个作为目标代码文件提供给学生的程序。运行时，它提示用户输入 6 个不同的字符串。如果其中的任何一个不正确，炸弹就会“爆炸”，打印出一条错误消息，并且在一个打分服务器上记录事件日志。学生必须通过对程序反汇编和逆向工程来测定应该是哪 6 个串，从而解除各自炸弹的雷管。该实验能教会学生理解汇编语言，并且强制他们学习怎样使用调试器。 缓冲区溢出实验。它要求学生通过利用一个缓冲区溢出漏洞，来修改一个二进制可执行文件的运行时行为。这个实验可教会学生栈的原理，并让他们了解写那种易于遭受缓冲区溢出攻击的代码的危险性。 体系结构实验。第 4 章的几个家庭作业能够组合成一个实验作业，在实验中，学生修改处理器的 HCL 描述，增加新的指令，修改分支预测策略，或者增加、删除旁路路径和寄存器端口。修改后的处理器能够被模拟，并通过运行自动化测试检测出大多数可能的错误。这个实验使学生能够体验处理器设计中令人激动的部分，而不需要掌握逻辑设计和硬件描述语言的完整知识。 性能实验。学生必须优化应用程序的核心函数（比如卷积积分或矩阵转置）的性能。这个实验可非常清晰地表明高速缓存的特性，并带给学生低级程序优化的经验。 cache 实验。这个实验类似于性能实验，学生编写一个通用高速缓存模拟器，并优化小型矩阵转置核心函数，以最小化对模拟的高速缓存的不命中次数。我们使用 Valgrind 为矩阵转置核心函数生成真实的地址访问记录。 shell实验。学生实现他们自己的带有作业控制的 Unix shell 程序，包括 Ctrl+C和 Ctrl+Z 按键，fg、bg和 jobs 命令。这是学生第一次接触并发，并且让他们对 Unix 的进程控制、信号和信号处理有清晰的了解。 malloc 实验。学生实现他们自己的 malloc、free 和 realloc（可选）版本。这个实验可让学生们清晰地理解数据的布局和组织，并且要求他们评估时间和空间效率的各种权衡及折中。 代理实验。实现一个位于浏览器和万维网其他部分之间的并行 Web 代理。这个实验向学生们揭示了 Web 客户端和服务器这样的主题，并且把课程中的许多概念联系起来，比如字节排序、文件 I&#x2F;O、进程控制、信号、信号处理、内存映射、套接字和并发。学生很高兴能够看到他们的程序在真实的 Web 浏览器和 Web 服务器之间起到的作用。 CS∶APP的教师手册中有对实验的详细讨论，还有关于下载支持软件的说明。"},{"path":"/wiki/storage/index.html","content":"请注意：本资源来源于网络，如有侵权请联系删除 都梁 《亮剑》 《血色浪漫》 《大崩溃》 《狼烟北平》 《荣宝斋》 大仲马 《基督山伯爵》 斯蒂芬·茨威格 《人类的群星闪耀时》 钱锺书 《围城》 乔治·奥威尔 《一九八四》 凯利·麦格尼格尔 《自控力经典套装三册》 乔斯坦·贾德 《苏菲的世界》 兰道尔·门罗 《那些古怪又让人忧心的问题》 路遥 《平凡的世界》 《人生》 米克罗斯·尼兹利 《逃离奥斯维辛》 史铁生 《我与地坛》 卡勒德·胡赛尼 《追风筝的人》 周梅森 《人民的名义》 计算机相关 《代码整洁之道》 《Go Web编程》 《Go程序设计语言》 《Go语言实战》 《Redis设计与实现》 《Redis实战》"},{"title":"第一章 研究Nginx前的准备工作","path":"/wiki/understanding-nginx:modules-development-and-architecture-resolving(second-edition)/chapter_01.html","content":"2012年，Nginx荣获年度云计算开发奖（2012 Cloud Award for Developer of the Year），并成长为世界第二大Web服务器。全世界流量最高的前1000名网站中，超过25%都使用Nginx来处理海量的互联网请求。Nginx已经成为业界高性能Web服务器的代名词。那么，什么是Nginx？它有哪些特点？我们选择Nginx的理由是什么？如何编译安装Nginx？这种安装方式背后隐藏的又是什么样的思想呢？本章将会回答上述问题。 1.1 Nginx是什么人们在了解新事物时，往往习惯通过类比来帮助自己理解事物的概貌。那么，我们在学习Nginx时也采用同样的方式，先来看看Nginx的竞争对手——Apache、Lighttpd、Tomcat、Jetty、IIS，它们都是Web服务器，或者叫做WWW（World Wide Web）服务器，相应地也都具备Web服务器的基本功能：基于REST架构风格[1] ，以统一资源描述符（Uniform Resource Identifier，URI）或者统一资源定位符（Uniform Resource Locator，URL）作为沟通依据，通过HTTP为浏览器等客户端程序提供各种网络服务。然而，由于这些Web服务器在设计阶段就受到许多局限，例如当时的互联网用户规模、网络带宽、产品特点等局限，并且各自的定位与发展方向都不尽相同，使得每一款Web服务器的特点与应用场合都很鲜明。Tomcat和Jetty面向Java语言，先天就是重量级的Web服务器，它的性能与Nginx没有可比性，这里略过。IIS只能在Windows操作系统上运行。Windows作为服务器在稳定性与其他一些性能上都不如类UNIX操作系统，因此，在需要高性能Web服务器的场合下，IIS可能会被“冷落”。Apache的发展时期很长，而且是目前毫无争议的世界第一大Web服务器，图1-1中是12年来（2010~2012年）世界Web服务器的使用排名情况。 图1-1 Netcraft对于644275754个站点31.4M个域名Web服务器使用情况的调查结果（2012年3月） 从图1-1中可以看出，Apache目前处于领先地位。Apache有许多优点，如稳定、开源、跨平台等，但它出现的时间太长了，在它兴起的年代，互联网的产业规模远远比不上今天，所以它被设计成了一个重量级的、不支持高并发的Web服务器。在Apache服务器上，如果有数以万计的并发HTTP请求同时访问，就会导致服务器上消耗大量内存，操作系统内核对成百上千的Apache进程做进程间切换也会消耗大量CPU资源，并导致HTTP请求的平均响应速度降低，这些都决定了Apache不可能成为高性能Web服务器，这也促使了Lighttpd和Nginx的出现。观察图1-1中Nginx成长的曲线，体会一下Nginx抢占市场时的“咄咄逼人”吧。Lighttpd和Nginx一样，都是轻量级、高性能的Web服务器，欧美的业界开发者比较钟爱Lighttpd，而国内的公司更青睐Nginx，Lighttpd使用得比较少。在了解了Nginx的竞争对手之后，相信大家对Nginx也有了直观感受，下面让我们来正式地认识一下Nginx吧。 提示Nginx发音：engineX 来自俄罗斯的Igor Sysoev在为Rambler Media（http://www.rambler.ru/ ）工作期间，使用C语言开发了Nginx。Nginx作为Web服务器，一直为俄罗斯著名的门户网站Rambler Media提供着出色、稳定的服务。Igor Sysoev将Nginx的代码开源，并且赋予其最自由的2-clause BSD-like license[2] 许可证。由于Nginx使用基于事件驱动的架构能够并发处理百万级别的TCP连接，高度模块化的设计和自由的许可证使得扩展Nginx功能的第三方模块层出不穷，而且优秀的设计带来了极佳的稳定性，因此其作为Web服务器被广泛应用到大流量的网站上，包括腾讯、新浪、网易、淘宝等访问量巨大的网站。2012年2月和3月Netcraft对Web服务器的调查如表1-1所示，可以看出，Nginx的市场份额越来越大。 表1-1 Netcraft对于Web服务器市场占有率前4位软件的调查（2012年2月和3月） Nginx是一个跨平台的Web服务器，可运行在Linux、FreeBSD、Solaris、AIX、Mac OS、Windows等操作系统上，并且它还可以使用当前操作系统特有的一些高效API来提高自己的性能。例如，对于高效处理大规模并发连接，它支持Linux上的epoll（epoll是Linux上处理大并发网络连接的利器，9.6.1节中将会详细说明epoll的工作原理）、Solaris上的event ports和FreeBSD上的kqueue等。又如，对于Linux，Nginx支持其独有的sendfile系统调用，这个系统调用可以高效地把硬盘中的数据发送到网络上（不需要先把硬盘数据复制到用户态内存上再发送），这极大地减少了内核态与用户态数据间的复制动作。种种迹象都表明，Nginx以性能为王。2011年7月，Nginx正式成立公司，由Igor Sysoev担任CTO，立足于提供商业级的Web服务器。[1] 参见Roy Fielding博士的论文《Architectural Styles and the Design of Network-based Software Architectures》，可在http://www.ics.uci.edu/~fielding/pubs/dissertation/top.htm查看原文。[2] BSD（Berkeley Software Distribution）许可协议是自由软件（开源 软件的一个子集）中使用最广泛的许可协议之一。与其他许可协议相 比，BSD许可协议从GNU通用公共许可协议（GPL）到限制重重的著 作权（copyright）都要宽松一些，事实上，它跟公有领域更为接近。BSD许可协议被认为是copycenter（中间版权），界于标准的copyright与GPL的copyleft之间。2-clause BSD-like license是BSD许可协议中最宽 松的一种，它对开发者再次使用BSD软件只有两个基本的要求：一是 如果再发布的产品中包含源代码，则在源代码中必须带有原来代码中 的BSD协议；二是如果再发布的只是二进制类库&#x2F;软件，则需要在类库&#x2F;软件的文档和版权声明中包含原来代码中的BSD协议。 1.2 为什么选择Nginx为什么选择Nginx？因为它具有以下特点： 更快这表现在两个方面：一方面，在正常情况下，单次请求会得到更快的响应；另一方面，在高峰期（如有数以万计的并发请求），Nginx可以比其他Web服务器更快地响应请求。实际上，本书第三部分中大量的篇幅都是在说明Nginx是如何做到这两点的。 高扩展性Nginx的设计极具扩展性，它完全是由多个不同功能、不同层次、不同类型且耦合度极低的模块组成。因此，当对某一个模块修复Bug或进行升级时，可以专注于模块自身，无须在意其他。而且在HTTP模块中，还设计了HTTP过滤器模块：一个正常的HTTP模块在处理完请求后，会有一串HTTP过滤器模块对请求的结果进行再处理。这样，当我们开发一个新的HTTP模块时，不但可以使用诸如HTTP核心模块、events模块、log模块等不同层次或者不同类型的模块，还可以原封不动地复用大量已有的HTTP过滤器模块。这种低耦合度的优秀设计，造就了Nginx庞大的第三方模块，当然，公开的第三方模块也如官方发布的模块一样容易使用。Nginx的模块都是嵌入到二进制文件中执行的，无论官方发布的模块还是第三方模块都是如此。这使得第三方模块一样具备极其优秀的性能，充分利用Nginx的高并发特性，因此，许多高流量的网站都倾向于开发符合自己业务特性的定制模块。 高可靠性高可靠性是我们选择Nginx的最基本条件，因为Nginx的可靠性是大家有目共睹的，很多家高流量网站都在核心服务器上大规模使用Nginx。Nginx的高可靠性来自于其核心框架代码的优秀设计、模块设计的简单性；另外，官方提供的常用模块都非常稳定，每个worker进程相对独立，master进程在1个worker进程出错时可以快速“拉起”新的worker子进程提供服务。 低内存消耗一般情况下，10000个非活跃的HTTP Keep-Alive连接在Nginx中仅消耗2.5MB的内存，这是Nginx支持高并发连接的基础。从第3章开始，我们会接触到Nginx在内存中为了维护一个HTTP连接所分配的对象，届时将会看到，实际上Nginx一直在为用户考虑（尤其是在高并发时）如何使得内存的消耗更少。 单机支持10万以上的并发连接这是一个非常重要的特性！随着互联网的迅猛发展和互联网用户数量的成倍增长，各大公司、网站都需要应付海量并发请求，一个能够在峰值期顶住10万以上并发请求的Server，无疑会得到大家的青睐。理论上，Nginx支持的并发连接上限取决于内存，10万远未封顶。当然，能够及时地处理更多的并发请求，是与业务特点紧密相关的，本书第8~11章将会详细说明如何实现这个特点。 热部署master管理进程与worker工作进程的分离设计，使得Nginx能够提供热部署功能，即可以在7×24小时不间断服务的前提下，升级Nginx的可执行文件。当然，它也支持不停止服务就更新配置项、更换日志文件等功能。 最自由的BSD许可协议这是Nginx可以快速发展的强大动力。BSD许可协议不只是允许用户免费使用Nginx，它还允许用户在自己的项目中直接使用或修改Nginx源码，然后发布。这吸引了无数开发者继续为Nginx贡献自己的智慧。 以上7个特点当然不是Nginx的全部，拥有无数个官方功能模块、第三方功能模块使得Nginx能够满足绝大部分应用场景，这些功能模块间可以叠加以实现更加强大、复杂的功能，有些模块还支持Nginx与Perl、Lua等脚本语言集成工作，大大提高了开发效率。这些特点促使用户在寻找一个Web服务器时更多考虑Nginx。当然，选择Nginx的核心理由还是它能在支持高并发请求的同时保持高效的服务。如果Web服务器的业务访问量巨大，就需要保证在数以百万计的请求同时访问服务时，用户可以获得良好的体验，不会出现并发访问量达到一个数字后，新的用户无法获取服务，或者虽然成功地建立起了TCP连接，但大部分请求却得不到响应的情况。通常，高峰期服务器的访问量可能是正常情况下的许多倍，若有热点事件的发生，可能会导致正常情况下非常顺畅的服务器直接“挂 死”。然而，如果在部署服务器时，就预先针对这种情况进行扩容，又会使得正常情况下所有服务器的负载过低，这会造成大量的资源浪费。因此，我们会希望在这之间取得平衡，也就是说，在低并发压力下，用户可以获得高速体验，而在高并发压力下，更多的用户都能接入，可能访问速度会下降，但这只应受制于带宽和处理器的速度，而不应该是服务器设计导致的软件瓶颈。事实上，由于中国互联网用户群体的数量巨大，致使对Web服务器的设计往往要比欧美公司更加困难。例如，对于全球性的一些网站而言，欧美用户分布在两个半球，欧洲用户活跃时，美洲用户通常在休息，反之亦然。而国内巨大的用户群体则对业界的程序员提出更高的挑战，早上9点和晚上20点到24点这些时间段的并发请求压力是非常巨大的。尤其节假日、寒暑假到来之时，更会对服务器提出极高的要求。另外，国内业务上的特性，也会引导用户在同一时间大并发地访问服务器。例如，许多SNS网页游戏会在固定的时间点刷新游戏资源或者允许“偷菜”等好友互动操作。这些会导致服务器处理高并发请求的压力增大。上述情形都对我们的互联网服务在大并发压力下是否还能够给予用户良好的体验提出了更高的要求。若要提供更好的服务，那么可以从多方面入手，例如，修改业务特性、引导用户从高峰期分流或者把服务分层分级、对于不同并发压力给用户提供不同级别的服务等。但最根本的是，Web服务器要能支持大并发压力下的正常服务，这才是关键。快速增长的互联网用户群以及业内所有互联网服务提供商越来越好的用户体验，都促使我们在大流量服务中用Nginx取代其他Web服务器。Nginx先天的事件驱动型设计、全异步的网络I&#x2F;O处理机制、极少的进程间切换以及许多优化设计，都使得Nginx天生善于处理高并发压力下的互联网请求，同时Nginx降低了资源消耗，可以把服务器硬件资源“压榨”到极致。 1.3 准备工作由于Linux具有免费、使用广泛、商业支持越来越完善等特点，本书将主要针对Linux上运行的Nginx来进行介绍。需要说明的是，本书不是使用手册，而是介绍Nginx作为Web服务器的设计思想，以及如何更有效地使用Nginx达成目的，而这些内容在各操作系统上基本是相通的（除了第9章关于事件驱动方式以及第14章的进程间同步方式在类UNIX操作系统上略有不同以外）。 1.3.1 Linux操作系统首先我们需要一个内核为Linux 2.6及以上版本的操作系统，因为Linux 2.6及以上内核才支持epoll，而在Linux上使用select或poll来解决事件的多路复用，是无法解决高并发压力问题的。我们可以使用uname-a命令来查询Linux内核版本，例如： 12:wehf2wng001:root &gt; uname -aLinux wehf2wng001 2.6.18-128.el5 #1 SMP Wed Jan 21 10:41:14 EST 2009 x86_64 x86_64 x86_64 GNU/Linux 执行结果表明内核版本是2.6.18，符合我们的要求。 1.3.2 使用Nginx的必备软件如果要使用Nginx的常用功能，那么首先需要确保该操作系统上至少安装了如下软件。 GCC编译器GCC（GNU Compiler Collection）可用来编译C语言程序。Nginx不会直接提供二进制可执行程序（1.2.x版本中已经开始提供某些操作系统上的二进制安装包了，不过，本书探讨如何开发Nginx模块是必须通过直接编译源代码进行的），这有许多原因，本章后面会详述。我们可以使用最简单的yum方式安装GCC，例如：1yum install -y gcc GCC是必需的编译工具。在第3章会提到如何使用C++来编写Nginx HTTP模块，这时就需要用到G++编译器了。G++编译器也可以用yum安装，例如：1yum install -y gcc-c++ Linux上有许多软件安装方式，yum只是其中比较方便的一种，其他方式这里不再赘述。 PCRE库PCRE（Perl Compatible Regular Expressions，Perl兼容正则表达式）是由Philip Hazel开发的函数库，目前为很多软件所使用，该库支持正则表达式。它由RegEx演化而来，实际上，Perl正则表达式也是源自于Henry Spencer写的RegEx。如果我们在配置文件nginx.conf里使用了正则表达式，那么在编译Nginx时就必须把PCRE库编译进Nginx，因为Nginx的HTTP模块要靠它来解析正则表达式。当然，如果你确认不会使用正则表达式，就不必安装它。其yum安装方式如下：1yum install -y pcre pcre-devel pcre-devel是使用PCRE做二次开发时所需要的开发库，包括头文件等，这也是编译Nginx所必须使用的。 zlib库zlib库用于对HTTP包的内容做gzip格式的压缩，如果我们在nginx.conf里配置了gzip on，并指定对于某些类型（content-type）的HTTP响应使用gzip来进行压缩以减少网络传输量，那么，在编译时就必须把zlib编译进Nginx。其yum安装方式如下：1yum install -y zlib zlib-devel 同理，zlib是直接使用的库，zlib-devel是二次开发所需要的库。 OpenSSL开发库如果我们的服务器不只是要支持HTTP，还需要在更安全的SSL协议上传输HTTP，那么就需要拥有OpenSSL了。另外，如果我们想使用MD5、SHA1等散列函数，那么也需要安装它。其yum安装方式如下：1yum install -y openssl openssl-devel 上面所列的4个库只是完成Web服务器最基本功能所必需的。Nginx是高度自由化的Web服务器，它的功能是由许多模块来支持的。而这些模块可根据我们的使用需求来定制，如果某些模块不需要使用则完全不必理会它。同样，如果使用了某个模块，而这个模块使用了一些类似zlib或OpenSSL等的第三方库，那么就必须先安装这些软件。 1.3.3 磁盘目录要使用Nginx，还需要在Linux文件系统上准备以下目录。 Nginx源代码存放目录该目录用于放置从官网上下载的Nginx源码文件，以及第三方或我们自己所写的模块源代码文件。 Nginx编译阶段产生的中间文件存放目录该目录用于放置在configure命令执行后所生成的源文件及目录，以及make命令执行后生成的目标文件和最终连接成功的二进制文件。默认情况下，configure命令会将该目录命名为objs，并放在Nginx源代码目录下。 部署目录该目录存放实际Nginx服务运行期间所需要的二进制文件、配置文件等。默认情况下，该目录为&#x2F;usr&#x2F;local&#x2F;nginx。 日志文件存放目录日志文件通常会比较大，当研究Nginx的底层架构时，需要打开debug级别的日志，这个级别的日志非常详细，会导致日志文件的大小增长得极快，需要预先分配一个拥有更大磁盘空间的目录。 1.3.4 Linux内核参数的优化由于默认的Linux内核参数考虑的是最通用的场景，这明显不符合用于支持高并发访问的Web服务器的定义，所以需要修改Linux内核参数，使得Nginx可以拥有更高的性能。在优化内核时，可以做的事情很多，不过，我们通常会根据业务特点来进行调整，当Nginx作为静态Web内容服务器、反向代理服务器或是提供图片缩略图功能（实时压缩图片）的服务器时，其内核参数的调整都是不同的。这里只针对最通用的、使Nginx支持更多并发请求的TCP网络参数做简单说明。首先，需要修改&#x2F;etc&#x2F;sysctl.conf来更改内核参数。例如，最常用的配置： 123456789101112131415fs.file-max = 999999 net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_keepalive_time = 600net.ipv4.tcp_fin_timeout = 30net.ipv4.tcp_max_tw_buckets = 5000net.ipv4.ip_local_port_range = 1024 61000net.ipv4.tcp_rmem = 4096 32768 262142net.ipv4.tcp_wmem = 4096 32768 262142net.core.netdev_max_backlog = 8096net.core.rmem_default = 262144net.core.wmem_default = 262144net.core.rmem_max = 2097152net.core.wmem_max = 2097152net.ipv4.tcp_syncookies = 1net.ipv4.tcp_max_syn.backlog=1024 然后执行sysctl-p命令，使上述修改生效。上面的参数意义解释如下： file-max：这个参数表示进程（比如一个worker进程）可以同时打开的最大句柄数，这个参数直接限制最大并发连接数，需根据实际情况配置。 tcp_tw_reuse：这个参数设置为1，表示允许将TIME-WAIT状态的socket重新用于新的TCP连接，这对于服务器来说很有意义，因为服务器上总会有大量TIME-WAIT状态的连接。 tcp_keepalive_time：这个参数表示当keepalive启用时，TCP发送keepalive消息的频度。默认是2小时，若将其设置得小一些，可以更快地清理无效的连接。 tcp_fin_timeout：这个参数表示当服务器主动关闭连接时，socket保持在FIN-WAIT-2状态的最大时间。 tcp_max_tw_buckets：这个参数表示操作系统允许TIME_WAIT套接字数量的最大值，如果超过这个数字，TIME_WAIT套接字将立刻被清除并打印警告信息。该参数默认为180000，过多的TIME_WAIT套接字会使Web服务器变慢。 tcp_max_syn_backlog：这个参数表示TCP三次握手建立阶段接收SYN请求队列的最大长度，默认为1024，将其设置得大一些可以使出现Nginx繁忙来不及accept新连接的情况时，Linux不至于丢失客户端发起的连接请求。 ip_local_port_range：这个参数定义了在UDP和TCP连接中本地（不包括连接的远端）端口的取值范围。 net.ipv4.tcp_rmem：这个参数定义了TCP接收缓存（用于TCP接收滑动窗口）的最小值、默认值、最大值。 net.ipv4.tcp_wmem：这个参数定义了TCP发送缓存（用于TCP发送滑动窗口）的最小值、默认值、最大值。 netdev_max_backlog：当网卡接收数据包的速度大于内核处理的速度时，会有一个队列保存这些数据包。这个参数表示该队列的最大值。 rmem_default：这个参数表示内核套接字接收缓存区默认的大小。 wmem_default：这个参数表示内核套接字发送缓存区默认的大小。 rmem_max：这个参数表示内核套接字接收缓存区的最大大小。 wmem_max：这个参数表示内核套接字发送缓存区的最大大小。 注意滑动窗口的大小与套接字缓存区会在一定程度上影响并发连接的数目。每个TCP连接都会为维护TCP滑动窗口而消耗内存，这个窗口会根据服务器的处理速度收缩或扩张。参数wmem_max的设置，需要平衡物理内存的总大小、Nginx并发处理的最大连接数量（由nginx.conf中的worker_processes和worker_connections参数决定）而确定。当然，如果仅仅为了提高并发量使服务器不出现Out Of Memory问题而去降低滑动窗口大小，那么并不合适，因为滑动窗口过小会影响大数据量的传输速度。rmem_default、wmem_default、rmem_max、wmem_max这4个参数的设置需要根据我们的业务特性以及实际的硬件成本来综合考虑。 tcp_syncookies：该参数与性能无关，用于解决TCP的SYN攻击。 1.3.5 获取Nginx源码可以在Nginx官方网站（http://nginx.org/en/download.html ）获取Nginx源码包。将下载的nginx-1.0.14.tar.gz源码压缩包放置到准备好的Nginx源代码目录中，然后解压。例如： 1tar -zxvf nginx-1.0.14.tar.gz 本书编写时的Nginx最新稳定版本为1.0.14（如图1-2所示），本书后续部分都将以此版本作为基准。当然，本书将要说明的Nginx核心代码一般不会有改动（否则大量第三方模块的功能就无法保证了），即使下载其他版本的Nginx源码包也不会影响阅读本书。 图1-2 Nginx的不同版本 1.4 编译安装Nginx安装Nginx最简单的方式是，进入nginx-1.0.14目录后执行以下3行命令： 123./configuremakemake install configure命令做了大量的“幕后”工作，包括检测操作系统内核和已经安装的软件，参数的解析，中间目录的生成以及根据各种参数生成一些C源码文件、Makefile文件等。make命令根据configure命令生成的Makefile文件编译Nginx工程，并生成目标文件、最终的二进制文件。make install命令根据configure执行时的参数将Nginx部署到指定的安装目录，包括相关目录的建立和二进制文件、配置文件的复制。 1.5 configure详解可以看出，configure命令至关重要，下文将详细介绍如何使用configure命令，并分析configure到底是如何工作的，从中我们也可以看出Nginx的一些设计思想。 1.5.1 configure的命令参数1.路径相关的参数表1-2列出了Nginx在编译期、运行期中与路径相关的各种参数。 表1-2 configure支持的路径相关参数 2.编译相关的参数表1-3列出了编译Nginx时与编译器相关的参数。 表1-3 configure支持的编译相关参数 3.依赖软件的相关参数表1-4~表1-8列出了Nginx依赖的常用软件支持的参数。 表1-4 PCRE的设置参数 表1-5 OpenSSL的设置参数 表1-6 原子库的设置参数 表1-7 散列函数库的设置参数 表1-8 zlib库的设置参数 4.模块相关的参数除了少量核心代码外，Nginx完全是由各种功能模块组成的。这些模块会根据配置参数决定自己的行为，因此，正确地使用各个模块非常关键。在configure的参数中，我们把它们分为五大类。 事件模块。 默认即编译进入Nginx的HTTP模块。 默认不会编译进入Nginx的HTTP模块。 邮件代理服务器相关的mail模块。 其他模块。 事件模块表1-9中列出了Nginx可以选择哪些事件模块编译到产品中。表1-9 configure支持的事件模块参数 默认即编译进入Nginx的HTTP模块表1-10列出了默认就会编译进Nginx的核心HTTP模块，以及如何把这些HTTP模块从产品中去除。表1-10 configure中默认编译到Nginx中的HTTP模块参数 默认不会编译进入Nginx的HTTP模块表1-11列出了默认不会编译至Nginx中的HTTP模块以及把它们加入产品中的方法。表1-11 configure中默认不会编译到Nginx中的HTTP模块参数 邮件代理服务器相关的mail模块表1-12列出了把邮件模块编译到产品中的参数。表1-12 configure提供的邮件模块参数 其他参数configure还接收一些其他参数，表1-13中列出了相关参数的说明。表1-13 configure提供的其他参数 1.5.2 configure执行流程我们看到configure命令支持非常多的参数，读者可能会好奇它在执行时到底做了哪些事情，本节将通过解析configure源码来对它有一个感性的认识。configure由Shell脚本编写，中间会调用&#x2F;auto&#x2F;目录下的脚本。这里将只对configure脚本本身做分析，对于它所调用的auto目录下的其他工具脚本则只做功能性的说明。configure脚本的内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119#!/bin/sh# Copyright (C) Igor Sysoev# Copyright (C) Nginx, Inc.#auto/options脚本处理configure命令的参数。例如，如果参数是--help，那么显示支持的所有参数格式。options脚本会定义后续工作将要用到的变量，然后根据本次参数以及默认值设置这些变量. auto/options#auto/init脚本初始化后续将产生的文件路径。例如，Makefile、ngx_modules.c等文件默认情况下将会在&lt;nginx-source&gt;/objs/. auto/init#auto/sources脚本将分析Nginx的源码结构，这样才能构造后续的Makefile文件. auto/sources#编译过程中所有目标文件生成的路径由—builddir=DIR参数指定，默认情况下为&lt;nginx-source&gt;/objs，此时这个目录将会被创建test -d $NGX_OBJS || mkdir $NGX_OBJS#开始准备建立ngx_auto_headers.h、autoconf.err等必要的编译文件echo &gt; $NGX_AUTO_HEADERS_Hecho &gt; $NGX_AUTOCONF_ERR#向objs/ngx_auto_config.h写入命令行带的参数echo &quot;#define NGX_CONFIGURE \\&quot;$NGX_CONFIGURE\\&quot;&quot; &gt; $NGX_AUTO_CONFIG_H#判断DEBUG标志，如果有，那么在objs/ngx_auto_config.h文件中写入DEBUG宏if [ $NGX_DEBUG = YES ]; then have=NGX_DEBUG . auto/havefi#现在开始检查操作系统参数是否支持后续编译if test -z &quot;$NGX_PLATFORM&quot;; then echo &quot;checking for OS&quot; NGX_SYSTEM=`uname -s 2&gt;/dev/null` NGX_RELEASE=`uname -r 2&gt;/dev/null` NGX_MACHINE=`uname -m 2&gt;/dev/null`#屏幕上输出OS名称、内核版本、32位/64位内核 echo &quot; + $NGX_SYSTEM $NGX_RELEASE $NGX_MACHINE&quot; NGX_PLATFORM=&quot;$NGX_SYSTEM:$NGX_RELEASE:$NGX_MACHINE&quot;; case &quot;$NGX_SYSTEM&quot; in MINGW32_*) NGX_PLATFORM=win32 ;; esacelse echo &quot;building for $NGX_PLATFORM&quot; NGX_SYSTEM=$NGX_PLATFORMfi#检查并设置编译器，如GCC是否安装、GCC版本是否支持后续编译nginx. auto/cc/conf#对非Windows操作系统定义一些必要的头文件，并检查其是否存在，以此决定configure后续步骤是否可以成功[1]if [ &quot;$NGX_PLATFORM&quot; != win32 ]; then . auto/headersfi#对于当前操作系统，定义一些特定的操作系统相关的方法并检查当前环境是否支持。例如，对于Linux，在这里使用sched_setaffinity设置进程优先级，使用Linux特有的sendfile系统调用来加速向网络中发送文件块. auto/os/conf#定义类UNIX 操作系统中通用的头文件和系统调用等，并检查当前环境是否支持if [ &quot;$NGX_PLATFORM&quot; != win32 ]; then . auto/unixfi#最核心的构造运行期modules的脚本。它将会生成ngx_modules.c文件，这个文件会被编译进Nginx中，其中它所做的唯一的事情就是定义了ngx_modules数组。ngx_modules指明Nginx运行期间有哪些模块会参与到请求的处理中，包括HTTP请求可能会使用哪些模块处理，因此，它对数组元素的顺序非常敏感，也就是说，绝大部分模块在ngx_modules数组中的顺序其实是固定的。例如，一个请求必须先执行ngx_http_gzip_filter_module模块重新修改HTTP响应中的头部后，才能使用ngx_http_header_filter模块按照headers_in结构体里的成员构造出以TCP流形式发送给客户端的HTTP响应头部。注意，我们在--add-module=参数里加入的第三方模块也在此步骤写入到ngx_modules.c文件中了. auto/modules#conf脚本用来检查Nginx在链接期间需要链接的第三方静态库、动态库或者目标文件是否存在. auto/lib/conf#处理Nginx安装后的路径case &quot;.$NGX_PREFIX&quot; in .) NGX_PREFIX=$&#123;NGX_PREFIX:-/usr/local/nginx&#125; have=NGX_PREFIX value=&quot;\\&quot;$NGX_PREFIX/\\&quot;&quot; . auto/define ;; .!) NGX_PREFIX= ;; *) have=NGX_PREFIX value=&quot;\\&quot;$NGX_PREFIX/\\&quot;&quot; . auto/define ;;esac#处理Nginx安装后conf文件的路径if [ &quot;.$NGX_CONF_PREFIX&quot; != &quot;.&quot; ]; then have=NGX_CONF_PREFIX value=&quot;\\&quot;$NGX_CONF_PREFIX/\\&quot;&quot; . auto/definefi#处理Nginx安装后，二进制文件、pid、lock等其他文件的路径可参见configure参数中路径类选项的说明have=NGX_SBIN_PATH value=&quot;\\&quot;$NGX_SBIN_PATH\\&quot;&quot; . auto/definehave=NGX_CONF_PATH value=&quot;\\&quot;$NGX_CONF_PATH\\&quot;&quot; . auto/definehave=NGX_PID_PATH value=&quot;\\&quot;$NGX_PID_PATH\\&quot;&quot; . auto/definehave=NGX_LOCK_PATH value=&quot;\\&quot;$NGX_LOCK_PATH\\&quot;&quot; . auto/definehave=NGX_ERROR_LOG_PATH value=&quot;\\&quot;$NGX_ERROR_LOG_PATH\\&quot;&quot; . auto/definehave=NGX_HTTP_LOG_PATH value=&quot;\\&quot;$NGX_HTTP_LOG_PATH\\&quot;&quot; . auto/definehave=NGX_HTTP_CLIENT_TEMP_PATH value=&quot;\\&quot;$NGX_HTTP_CLIENT_TEMP_PATH\\&quot;&quot; . auto/definehave=NGX_HTTP_PROXY_TEMP_PATH value=&quot;\\&quot;$NGX_HTTP_PROXY_TEMP_PATH\\&quot;&quot; . auto/definehave=NGX_HTTP_FASTCGI_TEMP_PATH value=&quot;\\&quot;$NGX_HTTP_FASTCGI_TEMP_PATH\\&quot;&quot; . auto/definehave=NGX_HTTP_UWSGI_TEMP_PATH value=&quot;\\&quot;$NGX_HTTP_UWSGI_TEMP_PATH\\&quot;&quot; . auto/definehave=NGX_HTTP_SCGI_TEMP_PATH value=&quot;\\&quot;$NGX_HTTP_SCGI_TEMP_PATH\\&quot;&quot; . auto/define#创建编译时使用的objs/Makefile文件. auto/make#为objs/Makefile加入需要连接的第三方静态库、动态库或者目标文件. auto/lib/make#为objs/Makefile加入install功能，当执行make install时将编译生成的必要文件复制到安装路径，建立必要的目录. auto/install# 在ngx_auto_config.h文件中加入NGX_SUPPRESS_WARN宏、NGX_SMP宏. auto/stubs#在ngx_auto_config.h文件中指定NGX_USER和NGX_GROUP宏，如果执行configure时没有参数指定，默认两者皆为nobody（也就是默认以nobody用户运行进程）have=NGX_USER value=&quot;\\&quot;$NGX_USER\\&quot;&quot; . auto/definehave=NGX_GROUP value=&quot;\\&quot;$NGX_GROUP\\&quot;&quot; . auto/define#显示configure执行的结果，如果失败，则给出原因. auto/summary （注：在configure脚本里检查某个特性是否存在时，会生成一个最简单的只包含main函数的C程序，该程序会包含相应的头文件。然后，通过检查是否可以编译通过来确认特性是否支持，并将结果记录在objs&#x2F;autoconf.err文件中。后续检查头文件、检查特性的脚本都用了类似的方法。） 1.5.3 configure生成的文件当configure执行成功时会生成objs目录，并在该目录下产生以下目录和文件： 1234567891011121314151617|---ngx_auto_headers.h|---autoconf.err|---ngx_auto_config.h|---ngx_modules.c|---src| |---core| |---event| | |---modules| |---os| | |---unix| | |---win32| |---http| | |---modules| | | |---perl| |---mail| |---misc|---Makefile 上述目录和文件介绍如下。 src目录用于存放编译时产生的目标文件。 Makefile文件用于编译Nginx工程以及在加入install参数后安装Nginx。 autoconf.err保存configure执行过程中产生的结果。 ngx_auto_headers.h和ngx_auto_config.h保存了一些宏，这两个头文件会被src&#x2F;core&#x2F;ngx_config.h及src&#x2F;os&#x2F;unix&#x2F;ngx_linux_config.h文件（可将“linux”替换为其他UNIX操作系统）引用。 ngx_modules.c是一个关键文件，我们需要看看它的内部结构。一个默认配置下生成的ngx_modules.c文件内容如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;ngx_config.h&gt;#include &lt;ngx_core.h&gt;…ngx_module_t *ngx_modules[] = &#123;&amp;ngx_core_module,&amp;ngx_errlog_module,&amp;ngx_conf_module,&amp;ngx_events_module,&amp;ngx_event_core_module,&amp;ngx_epoll_module,&amp;ngx_http_module,&amp;ngx_http_core_module,&amp;ngx_http_log_module,&amp;ngx_http_upstream_module,&amp;ngx_http_static_module,&amp;ngx_http_autoindex_module,&amp;ngx_http_index_module,&amp;ngx_http_auth_basic_module,&amp;ngx_http_access_module,&amp;ngx_http_limit_zone_module,&amp;ngx_http_limit_req_module,&amp;ngx_http_geo_module,&amp;ngx_http_map_module,&amp;ngx_http_split_clients_module,&amp;ngx_http_referer_module,&amp;ngx_http_rewrite_module,&amp;ngx_http_proxy_module,&amp;ngx_http_fastcgi_module,&amp;ngx_http_uwsgi_module,&amp;ngx_http_scgi_module,&amp;ngx_http_memcached_module,&amp;ngx_http_empty_gif_module,&amp;ngx_http_browser_module,&amp;ngx_http_upstream_ip_hash_module,&amp;ngx_http_write_filter_module,&amp;ngx_http_header_filter_module,&amp;ngx_http_chunked_filter_module,&amp;ngx_http_range_header_filter_module,&amp;ngx_http_gzip_filter_module,&amp;ngx_http_postpone_filter_module,&amp;ngx_http_ssi_filter_module,&amp;ngx_http_charset_filter_module,&amp;ngx_http_userid_filter_module,&amp;ngx_http_headers_filter_module,&amp;ngx_http_copy_filter_module,&amp;ngx_http_range_body_filter_module,&amp;ngx_http_not_modified_filter_module,NULL&#125;; ngx_modules.c文件就是用来定义ngx_modules数组的。ngx_modules是非常关键的数组，它指明了每个模块在Nginx中的优先级，当一个请求同时符合多个模块的处理规则时，将按照它们在ngx_modules数组中的顺序选择最靠前的模块优先处理。对于HTTP过滤模块而言则是相反的，因为HTTP框架在初始化时，会在ngx_modules数组中将过滤模块按先后顺序向过滤链表中添加，但每次都是添加到链表的表头，因此，对HTTP过滤模块而言，在ngx_modules数组中越是靠后的模块反而会首先处理HTTP响应（参见第6章及第11章的11.9节）。因此，ngx_modules中模块的先后顺序非常重要，不正确的顺序会导致Nginx无法工作，这是auto&#x2F;modules脚本执行后的结果。读者可以体会一下上面的ngx_modules中同一种类型下（第8章会介绍模块类型，第10章、第11章将介绍的HTTP框架对HTTP模块的顺序是最敏感的）各个模块的顺序以及这种顺序带来的意义。可以看出，在安装过程中，configure做了大量的幕后工作，我们需要关注在这个过程中Nginx做了哪些事情。configure除了寻找依赖的软件外，还针对不同的UNIX操作系统做了许多优化工作。这是Nginx跨平台的一种具体实现，也体现了Nginx追求高性能的一贯风格。configure除了生成Makefile外，还生成了ngx_modules.c文件，它决定了运行时所有模块的优先级（在编译过程中而不是编码过程中）。对于不需要的模块，既不会加入ngx_modules数组，也不会编译进Nginx产品中，这也体现了轻量级的概念。[1] 在configure脚本里检查某个特性是否存在时，会生成一个最简单的只 包含main函数的C程序，该程序会包含相应的头文件。然后，通过检查是否可以编译通过来确认特性是否支持，并将结果记录在objs&#x2F;autoconf.err文件中。后续检查头文件、检查特性的脚本都用了类似的方法。 1.6 Nginx的命令行控制在Linux中，需要使用命令行来控制Nginx服务器的启动与停止、重载配置文件、回滚日志文件、平滑升级等行为。默认情况下，Nginx被安装在目录&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;中，其二进制文件路径为&#x2F;usr&#x2F;local&#x2F;nginc&#x2F;sbin&#x2F;nginx，配置文件路径为&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;nginx.conf。当然，在configure执行时是可以指定把它们安装在不同目录的。为了简单起见，本节只说明默认安装情况下的命令行的使用情况，如果读者安装的目录发生了变化，那么替换一下即可。 默认方式启动直接执行Nginx二进制程序。例如：1/usr/local/nginx/sbin/nginx 这时，会读取默认路径下的配置文件：&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;nginx.conf。实际上，在没有显式指定nginx.conf配置文件路径时，将打开在configure命令执行时使用–conf-path&#x3D;PATH指定的nginx.conf文件（参见1.5.1节）。 另行指定配置文件的启动方式使用-c参数指定配置文件。例如：1/usr/local/nginx/sbin/nginx -c /tmp/nginx.conf 这时，会读取-c参数后指定的nginx.conf配置文件来启动Nginx。 另行指定安装目录的启动方式使用-p参数指定Nginx的安装目录。例如：1/usr/local/nginx/sbin/nginx -p /usr/local/nginx/ 另行指定全局配置项的启动方式可以通过-g参数临时指定一些全局配置项，以使新的配置项生效。例如：1/usr/local/nginx/sbin/nginx -g &quot;pid /var/nginx/test.pid;&quot; 上面这行命令意味着会把pid文件写到&#x2F;var&#x2F;nginx&#x2F;test.pid中。-g参数的约束条件是指定的配置项不能与默认路径下的nginx.conf中的配置项相冲突，否则无法启动。就像上例那样，类似这样的配置项：pid logs&#x2F;nginx.pid，是不能存在于默认的nginx.conf中的。另一个约束条件是，以-g方式启动的Nginx服务执行其他命令行时，需要把-g参数也带上，否则可能出现配置项不匹配的情形。例如，如果要停止Nginx服务，那么需要执行下面代码：1/usr/local/nginx/sbin/nginx -g &quot;pid /var/nginx/test.pid;&quot; -s stop 如果不带上-g”pid&#x2F;var&#x2F;nginx&#x2F;test.pid;”，那么找不到pid文件，也会出现无法停止服务的情况。 测试配置信息是否有错误在不启动Nginx的情况下，使用-t参数仅测试配置文件是否有错误。例如：1/usr/local/nginx/sbin/nginx -t 执行结果中显示配置是否正确。 在测试配置阶段不输出信息测试配置选项时，使用-q参数可以不把error级别以下的信息输出到屏幕。例如：1/usr/local/nginx/sbin/nginx -t -q 显示版本信息使用-v参数显示Nginx的版本信息。例如：1/usr/local/nginx/sbin/nginx -v 显示编译阶段的参数使用-V参数除了可以显示Nginx的版本信息外，还可以显示配置编译阶段的信息，如GCC编译器的版本、操作系统的版本、执行configure时的参数等。例如：1/usr/local/nginx/sbin/nginx -V 快速地停止服务使用-s stop可以强制停止Nginx服务。-s参数其实是告诉Nginx程序向正在运行的Nginx服务发送信号量，Nginx程序通过nginx.pid文件中得到master进程的进程ID，再向运行中的master进程发送TERM信号来快速地关闭Nginx服务。例如：1/usr/local/nginx/sbin/nginx -s stop 实际上，如果通过kill命令直接向nginx master进程发送TERM或者INT信号，效果是一样的。例如，先通过ps命令来查看nginx master的进程ID：123:ahf5wapi001:root &gt; ps -ef | grep nginxroot 10800 1 0 02:27 ? 00:00:00 nginx: master process ./nginxroot 10801 10800 0 02:27 ? 00:00:00 nginx: worker process 接下来直接通过kill命令来发送信号：1kill -s SIGTERM 10800 或者：1kill -s SIGINT 10800 上述两条命令的效果与执行&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx-s stop是完全一样的。 “优雅”地停止服务如果希望Nginx服务可以正常地处理完当前所有请求再停止服务，那么可以使用-s quit参数来停止服务。例如：1/usr/local/nginx/sbin/nginx -s quit 该命令与快速停止Nginx服务是有区别的。当快速停止服务时，worker进程与master进程在收到信号后会立刻跳出循环，退出进程。而“优雅”地停止服务时，首先会关闭监听端口，停止接收新的连接，然后把当前正在处理的连接全部处理完，最后再退出进程。 与快速停止服务相似，可以直接发送QUIT信号给master进程来停止服务，其效果与执行-s quit命令是一样的。例如：1kill -s SIGQUIT &lt;nginx master pid&gt; 如果希望“优雅”地停止某个worker进程，那么可以通过向该进程发送WINCH信号来停止服务。例如：1kill -s SIGWINCH &lt;nginx worker pid&gt; 使运行中的Nginx重读配置项并生效使用-s reload参数可以使运行中的Nginx服务重新加载nginx.conf文件。例如：1/usr/local/nginx/sbin/nginx -s reload 事实上，Nginx会先检查新的配置项是否有误，如果全部正确就以“优雅”的方式关闭，再重新启动Nginx来实现这个目的。类似的，-s是发送信号，仍然可以用kill命令发送HUP信号来达到相同的效果。1kill -s SIGHUP &lt;nginx master pid&gt; 日志文件回滚使用-s reopen参数可以重新打开日志文件，这样可以先把当前日志文件改名或转移到其他目录中进行备份，再重新打开时就会生成新的日志文件。这个功能使得日志文件不至于过大。例如：1/usr/local/nginx/sbin/nginx -s reopen 当然，这与使用kill命令发送USR1信号效果相同。1kill -s SIGUSR1 &lt;nginx master pid&gt; 平滑升级Nginx当Nginx服务升级到新的版本时，必须要将旧的二进制文件Nginx替换掉，通常情况下这是需要重启服务的，但Nginx支持不重启服务来完成新版本的平滑升级。升级时包括以下步骤： 通知正在运行的旧版本Nginx准备升级。通过向master进程发送USR2信号可达到目的。例如：1kill -s SIGUSR2 &lt;nginx master pid&gt; 这时，运行中的Nginx会将pid文件重命名，如将&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;logs&#x2F;nginx.pid重命名为&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;logs&#x2F;nginx.pid.oldbin，这样新的Nginx才有可能启动成功。 启动新版本的Nginx，可以使用以上介绍过的任意一种启动方法。这时通过ps命令可以发现新旧版本的Nginx在同时运行。 通过kill命令向旧版本的master进程发送SIGQUIT信号，以“优雅”的方式关闭旧版本的Nginx。随后将只有新版本的Nginx服务运行，此时平滑升级完毕。 显示命令行帮助使用-h或者-?参数会显示支持的所有命令行参数。 1.7 小结本章介绍了Nginx的特点以及在什么场景下需要使用Nginx，同时介绍了如何获取Nginx以及如何配置、编译、安装运行Nginx。本章还深入介绍了最为复杂的configure过程，这部分内容是学习本书第二部分和第三部分的基础。"},{"title":"前言","path":"/wiki/understanding-nginx:modules-development-and-architecture-resolving(second-edition)/index.html","content":"请注意：本资源来源于网络，如有侵权请联系删除 为什么要写这本书自第1版发行以来，笔者很欣慰得到了广大读者的认可。本书一直致力于说明开发Nginx模块的必备知识，然而由于Nginx功能繁多且性能强大，以致必须要了解的基本技能也很庞杂，而第1版成书匆忙，缺失了几个进阶的技巧描述（例如如何使用变量、slab共享内存等），因此决定在第1版的基础上进一步完善。事实上，我们总能在nginx.conf配置文件中看到各种带着$符号的变量，只要修改带着变量的这一行行配置，就可以不用编译、部署而使得Nginx具备新功能，这些支持变量的Nginx模块提供了极为灵活的功能，第2版通过新增的第15章详细介绍了如何在模块中支持HTTP变量，包括如何在代码中使用其他Nginx模块提供的变量，以及如何定义新的变量供nginx.conf和其他第三方模块使用等。第16章介绍了slab共享内存，这是一套适用于小块内存快速分配释放的内存管理方式，它非常高效，分配与释放速度都是以纳秒计算的，常用于多个worker进程之间的通信，这比第14章介绍的原始的共享内存通信方式要先进很多。第16章不仅详细介绍了它的实现方式，也探讨了它的优缺点，比如，如果模块间要共享的单个对象常常要消耗数KB的空间，这时就需要修改它的实现（例如增大定义的slab页大小），以避免内存的浪费等。Nginx内存池在第1版中只是简单带过，第2版中新增了8.7节介绍了内存池的实现细节，以帮助读者用好最基础的内存池功能。此外，很多读者反馈需要结合TCP来谈谈Nginx，因此在9.10节中笔者试图在不陷入Linux内核细节的情况下，简要介绍了TCP以清晰了解Nginx的事件框架，了解Nginx的高并发能力。这一版新增的第15章的样例代码可以从http://nginx.taohui.org.cn 站点上下载。因笔者工作繁忙，以致第2版拖稿严重，读者的邮件也无法及时回复，非常抱歉。从这版开始会把曾经的回复整理后放在网站上，想必这比回复邮件要更有效率些。 读者对象本书适合以下读者阅读。 对Nginx及如何将它搭建成一个高性能的Web服务器感兴趣的读者。 希望通过开发特定的HTTP模块实现高性能Web服务器的读者。 希望了解Nginx的架构设计，学习其怎样充分使用服务器上的硬件资源的读者。 了解如何快速定位、修复Nginx中深层次Bug的读者。 希望利用Nginx提供的框架，设计出任何基于TCP的、无阻塞的、易于扩展的服务器的读者。 背景知识如果仅希望了解怎样使用已有的Nginx功能搭建服务器，那么阅读本书不需要什么先决条件。但如果希望通过阅读本书的第二、第三两部分，来学习Nginx的模块开发和架构设计技巧时，则必须了解C语言的基本语法。在阅读本书第三部分时，需要读者对TCP有一个基本的了解，同时对Linux操作系统也应该有简单的了解。 如何阅读本书我很希望将本书写成一本“step by step”式（循序渐进式）的书籍，因为这样最能节省读者的时间，然而，由于3个主要写作目的想解决的问题都不是那么简单，所以这本书只能做一个折中的处理。在第一部分的前两章中，将只探讨如何使用Nginx这一个问题。阅读这一部分的读者不需要了解C语言，就可以学习如何部署Nginx，学习如何向其中添加各种官方、第三方的功能模块，如何通过修改配置文件来更改Nginx及各模块的功能，如何修改Linux操作系统上的参数来优化服务器性能，最终向用户提供企业级的Web服务器。这一部分介绍配置项的方式，更偏重于领着对Nginx还比较陌生的读者熟悉它，通过了解几个基本Nginx模块的配置修改方式，进而使读者可以通过查询官网、第三方网站来了解如何使用所有Nginx模块的用法。在第二部分的第3章~第7章中，都是以例子来介绍HTTP模块的开发方式的，这里有些接近于“step by step”的学习方式，我在写作这一部分时，会通过循序渐进的方式使读者能够快速上手，同时会穿插着介绍其常见用法的基本原理。在第三部分，将开始介绍Nginx的完整框架，阅读到这里将会了解第二部分中HTTP模块为何以此种方式开发，同时将可以轻易地开发Nginx模块。这一部分并不仅仅满足于阐述Nginx架构，而是会探讨其为何如此设计，只有这样才能抛开HTTP框架、邮件代理框架，实现一种新的业务框架、一种新的模块类型。对于Nginx的使用还不熟悉的读者应当从第1章开始学习，前两章将帮助你快速了解Nginx。使用过Nginx，但对如何开发Nginx的HTTP模块不太了解的读者可以直接从第3章开始学习，在这一章阅读完后，即可编写一个功能大致完整的HTTP模块。然而，编写企业级的模块必须阅读完第4章才能做到，这一章将会介绍编写产品线上服务器程序时必备的3个手段。第5章举例说明了两种编写复杂HTTP模块的方式，在第三部分会对这两个方式有进一步的说明。第6章介绍一种特殊的HTTP模块——HTTP过滤模块的编写方法。第7章探讨基础容器的用法，这同样是复杂模块的必备工具。如果读者对于普通HTTP模块的编写已经很熟悉，想深入地实现更为复杂的HTTP模块，或者想了解邮件代理服务器的设计与实现，或者希望编写一种新的处理其他协议的模块，或者仅仅想了解Nginx的架构设计，都可以直接从第8章开始学习，这一章会从整体上系统介绍Nginx的模块式设计。第9章的事件框架是Nginx处理TCP的基础，这一章无法跳过。阅读第8章、第9章时可能会遇到许多第7章介绍过的容器，这时可以回到第7章查询其用法和意义。第10章~第12章在介绍HTTP框架，通过这3章的学习会对HTTP模块的开发有深入的了解，同时可以学习HTTP框架的优秀设计。第13章简单介绍了邮件代理服务器的设计，它近似于简化版的HTTP框架。第14章介绍了进程间同步的工具。第15章介绍了HTTP变量，包括如何使用已有变量、支持用户在nginx.conf中修改变量的值、支持其他模块开发者使用自己定义的变量等。第16章介绍了slab共享内存，该内存极为高效，可用于多个worker进程间的通信。为了不让读者陷入代码的“汪洋大海”中，在本书中大量使用了图表，这样可以使读者快速、大体地了解流程和原理，在这基础上，如果读者还希望了解代码是如何实现的，可以针对性地阅读源代码中的相应方法。在代码的关键地方会通过添加注释的方式加以说明。希望这种方式能够帮助读者减少阅读花费的时间，更快、更好地把握住Nginx，同时深入到细节中。写作本书第1版时，Nginx的最新稳定版本是1.0.14，所以当时是基于此版本来写作的。截止到第2版完成时，Nginx的稳定版本已经上升到了1.8.0。但这不会对本书的阅读造成困惑，笔者验证过示例代码，均可以运行在最新版本的Nginx中，这是因为本书主要是在介绍Nginx的基本框架代码，以及怎样使用这些框架代码开发新的Nginx模块。在这些基本框架代码中，Nginx一般不会做任何改变，否则已有的大量Nginx模块将无法工作，这种损失是不可承受的。而且Nginx框架为具体的功能模块提供了足够的灵活性，修改功能时很少需要修改框架代码。Nginx是跨平台的服务器，然而这本书将只针对于最常见的Linux操作系统进行分析，这样做一方面是篇幅所限，另一方面则是本书的写作目的主要在于告诉大家如何基于Nginx编写代码，而不是怎样在一个具体的操作系统上修改配置使用Nginx。因此，即使本书以Linux系统为代表讲述Nginx，也不会影响使用其他操作系统的读者阅读，操作系统的差别相对于本书内容的影响实在是非常小。 勘误与支持由于作者的水平有限，加之编写的时间也很仓促，书中难免会出现一些错误或者不准确的地方，恳请读者批评指正。为此，我特意创建了一个在线支持与应急方案的二级站点：http://nginx.weebly.com 。读者可以将书中的错误发布在Bug勘误表页面中，同时如果读者遇到任何问题，也可以访问Q&amp;A页面，我将尽量在线上为读者提供最满意的解答。书中的全部源文件都将发布在这个网站上，我也会将相应的功能更新及时发布出来。如果你有更多的宝贵意见，也欢迎你发送邮件至我的邮箱&#114;&#117;&#x73;&#x73;&#x65;&#108;&#108;&#116;&#97;&#x6f;&#x40;&#x66;&#x6f;&#x78;&#109;&#97;&#x69;&#108;&#x2e;&#x63;&#x6f;&#109;，期待能够听到读者的真挚反馈。 致谢我首先要感谢Igor Sysoev，他在Nginx设计上展现的功力令人折服，正是他的工作成果才有了本书诞生的意义。lisa是机械工业出版社华章公司的优秀编辑，非常值得信任。在这半年的写作过程中，她花费了很多时间、精力来阅读我的书稿，指出了许多文字上和格式上的错误，她提出的建议都大大提高了本书的可读性。在这半年时间里，一边工作一边写作给我带来了很大的压力，所以我要感谢我的父母在生活上对我无微不至的照顾，使我可以全力投入到写作中。繁忙的工作之余，写作又占用了休息时间的绝大部分，感谢我的太太毛业勤对我的体谅和鼓励，让我始终以高昂的斗志投入到本书的写作中。感谢我工作中的同事们，正是在与他们一起战斗在一线的日子里，我才不断地对技术有新地感悟；正是那些“充满激情的岁月，才使得我越来越热爱服务器技术的开发。谨以此书，献给我最亲爱的家人，以及众多热爱Nginx的朋友。—— 2015年10月 陶辉"},{"title":"写在前面","path":"/wiki/understanding-nginx:modules-development-and-architecture-resolving(second-edition)/section_01.html","content":"第一章 研究Nginx前的准备工作 第二章 Nginx的配置"},{"title":"第二章 Nginx的配置","path":"/wiki/understanding-nginx:modules-development-and-architecture-resolving(second-edition)/chapter_02.html","content":"Nginx拥有大量官方发布的模块和第三方模块，这些已有的模块可以帮助我们实现Web服务器上很多的功能。使用这些模块时，仅仅需要增加、修改一些配置项即可。因此，本章的目的是熟悉Nginx的配置文件，包括配置文件的语法格式、运行所有Nginx服务必须具备的基础配置以及使用HTTP核心模块配置静态Web服务器的方法，最后还会介绍反向代理服务器。通过本章的学习，读者可以：熟练地配置一个静态Web服务器；对影响Web服务器性能的各个配置项有深入的理解；对配置语法有全面的了解。通过互联网或其他途径得到任意模块的配置说明，然后可通过修改nginx.conf文件来使用这些模块的功能。 2.1 运行中的Nginx进程间的关系在正式提供服务的产品环境下，部署Nginx时都是使用一个master进程来管理多个worker进程，一般情况下，worker进程的数量与服务器上的CPU核心数相等。每一个worker进程都是繁忙的，它们在真正地提供互联网服务，master进程则很“清闲”，只负责监控管理worker进程。worker进程之间通过共享内存、原子操作等一些进程间通信机制来实现负载均衡等功能（第9章将会介绍负载均衡机制，第14章将会介绍负载均衡锁的实现）。部署后Nginx进程间的关系如图2-1所示。Nginx是支持单进程（master进程）提供服务的，那么为什么产品环境下要按照master-worker方式配置同时启动多个进程呢？这样做的好处主要有以下两点： 由于master进程不会对用户请求提供服务，只用于管理真正提供服务的worker进程，所以master进程可以是唯一的，它仅专注于自己的纯管理工作，为管理员提供命令行服务，包括诸如启动服务、停止服务、重载配置文件、平滑升级程序等。master进程需要拥有较大的权限，例如，通常会利用root用户启动master进程。worker进程的权限要小于或等于master进程，这样master进程才可以完全地管理worker进程。当任意一个worker进程出现错误从而导致coredump时，master进程会立刻启动新的worker进程继续服务。 多个worker进程处理互联网请求不但可以提高服务的健壮性（一个worker进程出错后，其他worker进程仍然可以正常提供服务），最重要的是，这样可以充分利用现在常见的SMP多核架构，从而实现微观上真正的多核并发处理。因此，用一个进程（master进程）来处理互联网请求肯定是不合适的。另外，为什么要把worker进程数量设置得与CPU核心数量一致呢？这正是Nginx与Apache服务器的不同之处。在Apache上每个进程在一个时刻只处理一个请求，因此，如果希望Web服务器拥有并发处理的请求数更多，就要把Apache的进程或线程数设置得更多，通常会达到一台服务器拥有几百个工作进程，这样大量的进程间切换将带来无谓的系统资源消耗。而Nginx则不然，一个worker进程可以同时处理的请求数只受限于内存大小，而且在架构设计上，不同的worker进程之间处理并发请求时几乎没有同步锁的限制，worker进通常不会进入睡眠状态，因此，当Nginx上的进程数与CPU核心数相等时（最好每一个worker进程都绑定特定的CPU核心），进程间切换的代价是最小的。图2-1 部署后Nginx进程间的关系 举例来说，如果产品中的服务器CPU核心数为8，那么就需要配置8个worker进程（见图2-2）。 图2-2 worker进程的数量尽量与CPU核心数相等 如果对路径部分都使用默认配置，那么Nginx运行目录为&#x2F;usr&#x2F;local&#x2F;nginx，其目录结构如下。 123456789101112131415161718192021222324252627282930|---sbin| |---nginx|---conf| |---koi-win| |---koi-utf| |---win-utf| |---mime.types| |---mime.types.default| |---fastcgi_params| |---fastcgi_params.default| |---fastcgi.conf| |---fastcgi.conf.default| |---uwsgi_params| |---uwsgi_params.default| |---scgi_params| |---scgi_params.default| |---nginx.conf| |---nginx.conf.default|---logs| |---error.log| |---access.log| |---nginx.pid|---html| |---50x.html| |---index.html|---client_body_temp|---proxy_temp|---fastcgi_temp|---uwsgi_temp|---scgi_temp 2.2 Nginx配置的通用语法Nginx的配置文件其实是一个普通的文本文件。下面来看一个简单的例子。 1234567891011121314151617user nobody;worker_processes 8;error_log /var/log/nginx/error.log error;#pid logs/nginx.pid;events &#123; use epoll; worker_connections 50000;&#125;http &#123; include mime.types; default_type application/octet-stream; log_format main &#x27;$remote_addr [$time_local] &quot;$request&quot; &#x27; &#x27;$status $bytes_sent &quot;$http_referer&quot; &#x27; &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;; access_log logs/access.log main buffer=32k; ...｝ 在这段简短的配置代码中，每一行配置项的语法格式都将在2.2.2节介绍，出现的events和http块配置项将在2.2.1节介绍，以#符号开头的注释将在2.2.3节介绍，类似“buffer&#x3D;32k”这样的配置项的单位将在2.2.4节介绍。 2.2.1 块配置项块配置项由一个块配置项名和一对大括号组成。具体示例如下： 12345678910111213events &#123;... &#125;http &#123; upstream backend &#123; server 127.0.0.1:8080; &#125; gzip on; server &#123; ... location /webstatic &#123; gzip off; &#125; &#125;&#125; 上面代码段中的events、http、server、location、upstream等都是块配置项，块配置项之后是否如“location&#x2F;webstatic{…}”那样在后面加上参数，取决于解析这个块配置项的模块，不能一概而论，但块配置项一定会用大括号把一系列所属的配置项全包含进来，表示大括号内的配置项同时生效。所有的事件类配置都要在events块中，http、server等配置也遵循这个规定。块配置项可以嵌套。内层块直接继承外层块，例如，上例中，server块里的任意配置都是基于http块里的已有配置的。当内外层块中的配置发生冲突时，究竟是以内层块还是外层块的配置为准，取决于解析这个配置项的模块，第4章将会介绍http块内配置项冲突的处理方法。例如，上例在http模块中已经打开了“gzip on;”，但其下的location&#x2F;webstatic又把gzip关闭了：gzip off;，最终，在&#x2F;webstatic的处理模块中，gzip模块是按照gzip off来处理请求的。 2.2.2 配置项的语法格式从上文的示例可以看出，最基本的配置项语法格式如下： 123配置项名 配置项值1 配置项值2 ... ; 下面解释一下配置项的构成部分。首先，在行首的是配置项名，这些配置项名必须是Nginx的某一个模块想要处理的，否则Nginx会认为配置文件出现了非法的配置项名。配置项名输入结束后，将以空格作为分隔符。其次是配置项值，它可以是数字或字符串（当然也包括正则表达式）。针对一个配置项，既可以只有一个值，也可以包含多个值，配置项值之间仍然由空格符来分隔。当然，一个配置项对应的值究竟有多少个，取决于解析这个配置项的模块。我们必须根据某个Nginx模块对一个配置项的约定来更改配置项，第4章将会介绍模块是如何约定一个配置项的格式。最后，每行配置的结尾需要加上分号。 注意如果配置项值中包括语法符号，比如空格符，那么需要使用单引号或双引号括住配置项值，否则Nginx会报语法错误。例如：log_format main $remote_addr - $remote_user [$time_local] “$request” ; 2.2.3 配置项的注释如果有一个配置项暂时需要注释掉，那么可以加“#”注释掉这一行配置。例如： 1#pid logs/nginx.pid; 2.2.4 配置项的单位大部分模块遵循一些通用的规定，如指定空间大小时不用每次都定义到字节、指定时间时不用精确到毫秒。当指定空间大小时，可以使用的单位包括： K或者k千字节（KiloByte，KB）。 M或者m兆字节（MegaByte，MB）。例如：12gzip_buffers 4 8k;client_max_body_size 64M; 当指定时间时，可以使用的单位包括： ms（毫秒），s（秒），m（分钟），h（小时），d（天），w（周，包含7天），M（月，包含30天），y（年，包含365天）。例如：123expires 10y;proxy_read_timeout 600;client_body_timeout 2m; 注意配置项后的值究竟是否可以使用这些单位，取决于解析该配置项的模块。如果这个模块使用了Nginx框架提供的相应解析配置项方法，那么配置项值才可以携带单位。第4章中详细描述了Nginx框架提供的14种预设解析方法，其中一些方法将可以解析以上列出的单位。 2.2.5 在配置中使用变量有些模块允许在配置项中使用变量，如在日志记录部分，具体示例如下。 123log_format main &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27; &#x27;$status $bytes_sent &quot;$http_referer&quot; &#x27; &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;; 其中，remote_addr是一个变量，使用它的时候前面要加上$符号。需要注意的是，这种变量只有少数模块支持，并不是通用的。许多模块在解析请求时都会提供多个变量（如本章后面提到的http core module、http proxy module、http upstream module等），以使其他模块的配置可以即时使用。我们在学习某个模块提供的配置说明时可以关注它是否提供变量。 提示在执行configure命令时，我们已经把许多模块编译进Nginx中，但是否启用这些模块，一般取决于配置文件中相应的配置项。换句话说，每个Nginx模块都有自己感兴趣的配置项，大部分模块都必须在nginx.conf中读取某个配置项后才会在运行时启用。例如，只有当配置http{…}这个配置项时，ngx_http_module模块才会在Nginx中启用，其他依赖ngx_http_module的模块也才能正常使用。 2.3 Nginx服务的基本配置Nginx在运行时，至少必须加载几个核心模块和一个事件类模块。这些模块运行时所支持的配置项称为基本配置——所有其他模块执行时都依赖的配置项。下面详述基本配置项的用法。由于配置项较多，所以把它们按照用户使用时的预期功能分成了以下4类： 用于调试、定位问题的配置项。 正常运行的必备配置项。 优化性能的配置项。 事件类配置项（有些事件类配置项归纳到优化性能类，这是因为它们虽然也属于events{}块，但作用是优化性能）。 有这么一些配置项，即使没有显式地进行配置，它们也会有默认的值，如daemon，即使在nginx.conf中没有对它进行配置，也相当于打开了这个功能，这点需要注意。对于这样的配置项，作者会在下面相应的配置项描述上加入一行“默认：”来进行说明。 2.3.1 用于调试进程和定位问题的配置项先来看一下用于调试进程、定位问题的配置项，如下所示。 是否以守护进程方式运行Nginx语法： daemon on|off;默认： daemon on;守护进程（daemon）是脱离终端并且在后台运行的进程。它脱离终端是为了避免进程执行过程中的信息在任何终端上显示，这样一来，进程也不会被任何终端所产生的信息所打断。Nginx毫无疑问是一个需要以守护进程方式运行的服务，因此，默认都是以这种方式运行的。不过Nginx还是提供了关闭守护进程的模式，之所以提供这种模式，是为了方便跟踪调试Nginx，毕竟用gdb调试进程时最烦琐的就是如何继续跟进fork出的子进程了。这在第三部分研究Nginx架构时很有用。 是否以master&#x2F;worker方式工作语法： master_process on|off;默认： master_process on;可以看到，在如图2-1所示的产品环境中，是以一个master进程管理多个worker进程的方式运行的，几乎所有的产品环境下，Nginx都以这种方式工作。与daemon配置相同，提供master_process配置也是为了方便跟踪调试Nginx。如果用off关闭了master_process方式，就不会fork出worker子进程来处理请求，而是用master进程自身来处理请求。 error日志的设置语法： error_log/path/file level;默认： error_log logs/error.log error;error日志是定位Nginx问题的最佳工具，我们可以根据自己的需求妥善设置error日志的路径和级别。&#x2F;path&#x2F;file参数可以是一个具体的文件，例如，默认情况下是logs&#x2F;error.log文件，最好将它放到一个磁盘空间足够大的位置；&#x2F;path&#x2F;file也可以是&#x2F;dev&#x2F;null，这样就不会输出任何日志了，这也是关闭error日志的唯一手段；&#x2F;path&#x2F;file也可以是stderr，这样日志会输出到标准错误文件中。level是日志的输出级别，取值范围是debug、info、notice、warn、error、crit、alert、emerg，从左至右级别依次增大。当设定为一个级别时，大于或等于该级别的日志都会被输出到&#x2F;path&#x2F;file文件中，小于该级别的日志则不会输出。例如，当设定为error级别时，error、crit、alert、emerg级别的日志都会输出。如果设定的日志级别是debug，则会输出所有的日志，这样数据量会很大，需要预先确保&#x2F;path&#x2F;file所在磁盘有足够的磁盘空间。注意如果日志级别设定到debug，必须在configure时加入–with-debug配置项。 是否处理几个特殊的调试点语法： debug_points[stop|abort]这个配置项也是用来帮助用户跟踪调试Nginx的。它接受两个参数：stop和abort。Nginx在一些关键的错误逻辑中（Nginx 1.0.14版本中有8处）设置了调试点。如果设置了debug_points为stop，那么Nginx的代码执行到这些调试点时就会发出SIGSTOP信号以用于调试。如果debug_points设置为abort，则会产生一个coredump文件，可以使用gdb来查看Nginx当时的各种信息。通常不会使用这个配置项。 仅对指定的客户端输出debug级别的日志语法： debug_connection[IP|CIDR]这个配置项实际上属于事件类配置，因此，它必须放在events{…} 中才有效。它的值可以是IP地址或CIDR地址，例如：1234events &#123; debug_connection 10.224.66.14; debug_connection 10.224.57.0/24;&#125; 这样，仅仅来自以上IP地址的请求才会输出debug级别的日志，其他请求仍然沿用error_log中配置的日志级别。上面这个配置对修复Bug很有用，特别是定位高并发请求下才会发生的问题。注意使用debug_connection前，需确保在执行configure时已经加入了–with-debug参数，否则不会生效。 限制coredump核心转储文件的大小语法： worker_rlimit_core size;在Linux系统中，当进程发生错误或收到信号而终止时，系统会将进程执行时的内存内容（核心映像）写入一个文件（core文件），以作为调试之用，这就是所谓的核心转储（core dumps）。当Nginx进程出现一些非法操作（如内存越界）导致进程直接被操作系统强制结束时，会生成核心转储core文件，可以从core文件获取当时的堆栈、寄存器等信息，从而帮助我们定位问题。但这种core文件中的许多信息不一定是用户需要的，如果不加以限制，那么可能一个core文件会达到几GB，这样随便coredumps几次就会把磁盘占满，引发严重问题。通过worker_rlimit_core配置可以限制core文件的大小，从而有效帮助用户定位问题。 指定coredump文件生成目录语法： working_directory path;worker进程的工作目录。这个配置项的唯一用途就是设置coredump文件所放置的目录，协助定位问题。因此，需确保worker进程有权限向working_directory指定的目录中写入文件。 2.3.2 正常运行的配置项下面是正常运行的配置项的相关介绍。 定义环境变量语法： env VAR|VAR=VALUE这个配置项可以让用户直接设置操作系统上的环境变量。例如：1env TESTPATH=/tmp/; 嵌入其他配置文件语法： include/path/file;include配置项可以将其他配置文件嵌入到当前的nginx.conf文件中，它的参数既可以是绝对路径，也可以是相对路径（相对于Nginx的配置目录，即nginx.conf所在的目录），例如：12include mime.types;include vhost/*.conf; 可以看到，参数的值可以是一个明确的文件名，也可以是含有通配符*的文件名，同时可以一次嵌入多个配置文件。 pid文件的路径语法： pid path/file;默认： pid logs/nginx.pid;保存master进程ID的pid文件存放路径。默认与configure执行时的参数“–pid-path”所指定的路径是相同的，也可以随时修改，但应确保Nginx有权在相应的目标中创建pid文件，该文件直接影响Nginx是否可以运行。 Nginx worker进程运行的用户及用户组语法： user username[groupname];默认： user nobody nobody;user用于设置master进程启动后，fork出的worker进程运行在哪个用户和用户组下。当按照“user username;”设置时，用户组名与用户名相同。若用户在configure命令执行时使用了参数–user&#x3D;username和–group&#x3D;groupname，此时nginx.conf将使用参数中指定的用户和用户组。 指定Nginx worker进程可以打开的最大句柄描述符个数语法： worker_rlimit_nofile limit;设置一个worker进程可以打开的最大文件句柄数。 限制信号队列语法： worker_rlimit_sigpending limit;设置每个用户发往Nginx的信号队列的大小。也就是说，当某个用户的信号队列满了，这个用户再发送的信号量会被丢掉。 2.3.3 优化性能的配置项下面是优化性能的配置项的相关介绍。 Nginx worker进程个数语法： worker_processes number;默认： worker_processes 1;在master&#x2F;worker运行方式下，定义worker进程的个数。worker进程的数量会直接影响性能。那么，用户配置多少个worker进程才好呢？这实际上与业务需求有关。每个worker进程都是单线程的进程，它们会调用各个模块以实现多种多样的功能。如果这些模块确认不会出现阻塞式的调用，那么，有多少CPU内核就应该配置多少个进程；反之，如果有可能出现阻塞式调用，那么需要配置稍多一些的worker进程。例如，如果业务方面会致使用户请求大量读取本地磁盘上的静态资源文件，而且服务器上的内存较小，以至于大部分的请求访问静态资源文件时都必须读取磁盘（磁头的寻址是缓慢的），而不是内存中的磁盘缓存，那么磁盘I&#x2F;O调用可能会阻塞住worker进程少量时间，进而导致服务整体性能下降。多worker进程可以充分利用多核系统架构，但若worker进程的数量多于CPU内核数，那么会增大进程间切换带来的消耗（Linux是抢占式内核）。一般情况下，用户要配置与CPU内核数相等的worker进程，并且使用下面的worker_cpu_affinity配置来绑定CPU内核。 绑定Nginx worker进程到指定的CPU内核语法： worker_cpu_affinity cpumask[cpumask...]为什么要绑定worker进程到指定的CPU内核呢？假定每一个worker进程都是非常繁忙的，如果多个worker进程都在抢同一个CPU，那么这就会出现同步问题。反之，如果每一个worker进程都独享一个CPU，就在内核的调度策略上实现了完全的并发。例如，如果有4颗CPU内核，就可以进行如下配置：12worker_processes 4;worker_cpu_affinity 1000 0100 0010 0001; 注意worker_cpu_affinity配置仅对Linux操作系统有效。Linux操作系统使用sched_setaffinity()系统调用实现这个功能。 SSL硬件加速语法： ssl_engine device；如果服务器上有SSL硬件加速设备，那么就可以进行配置以加快SSL协议的处理速度。用户可以使用OpenSSL提供的命令来查看是否有SSL硬件加速设备：1openssl engine -t 系统调用gettimeofday的执行频率语法： timer_resolution t;默认情况下，每次内核的事件调用（如epoll、select、poll、kqueue等）返回时，都会执行一次gettimeofday，实现用内核的时钟来更新Nginx中的缓存时钟。在早期的Linux内核中，gettimeofday的执行代价不小，因为中间有一次内核态到用户态的内存复制。当需要降低gettimeofday的调用频率时，可以使用timer_resolution配置。例如，“timer_resolution 100ms；”表示至少每100ms才调用一次gettimeofday。但在目前的大多数内核中，如x86-64体系架构，gettimeofday只是一次vsyscall，仅仅对共享内存页中的数据做访问，并不是通常的系统调用，代价并不大，一般不必使用这个配置。而且，如果希望日志文件中每行打印的时间更准确，也可以使用它。 Nginx worker进程优先级设置语法： worker_priority nice;默认： worker_priority 0;该配置项用于设置Nginx worker进程的nice优先级。在Linux或其他类UNIX操作系统中，当许多进程都处于可执行状态时，将按照所有进程的优先级来决定本次内核选择哪一个进程执行。进程所分配的CPU时间片大小也与进程优先级相关，优先级越高，进程分配到的时间片也就越大（例如，在默认配置下，最小的时间片只有5ms，最大的时间片则有800ms）。这样，优先级高的进程会占有更多的系统资源。优先级由静态优先级和内核根据进程执行情况所做的动态调整（目前只有±5的调整）共同决定。nice值是进程的静态优先级，它的取值范围是–20~+19，–20是最高优先级，+19是最低优先级。因此，如果用户希望Nginx占有更多的系统资源，那么可以把nice值配置得更小一些，但不建议比内核进程的nice值（通常为–5）还要小。 2.3.4 事件类配置项下面是事件类配置项的相关介绍。 是否打开accept锁语法： accept_mutex[on|off]默认： accept_mutext on;accept_mutex是Nginx的负载均衡锁，本书会在第9章事件处理框架中详述Nginx是如何实现负载均衡的。这里，读者仅需要知道accept_mutex这把锁可以让多个worker进程轮流地、序列化地与新的客户端建立TCP连接。当某一个worker进程建立的连接数量达到worker_connections配置的最大连接数的7&#x2F;8时，会大大地减小该worker进程试图建立新TCP连接的机会，以此实现所有worker进程之上处理的客户端请求数尽量接近。accept锁默认是打开的，如果关闭它，那么建立TCP连接的耗时会更短，但worker进程之间的负载会非常不均衡，因此不建议关闭它。 lock文件的路径语法： lock_file path/file;默认： lock_file logs/nginx.lock;accept锁可能需要这个lock文件，如果accept锁关闭，lock_file配置完全不生效。如果打开了accept锁，并且由于编译程序、操作系统架构等因素导致Nginx不支持原子锁，这时才会用文件锁实现accept锁 （14.8.1节将会介绍文件锁的用法），这样lock_file指定的lock文件才会生效。注意在基于i386、AMD64、Sparc64、PPC64体系架构的操作系统上，若使用GCC、Intel C++、SunPro C++编译器来编译Nginx，则可以肯定这时的Nginx是支持原子锁的，因为Nginx会利用CPU的特性并用汇编语言来实现它（可以参考14.3节x86架构下原子操作的实现）。这时的lock_file配置是没有意义的。 使用accept锁后到真正建立连接之间的延迟时间语法： accept_mutex_delay Nms;默认： accept_mutex_delay 500ms;在使用accept锁后，同一时间只有一个worker进程能够取到accept锁。这个accept锁不是阻塞锁，如果取不到会立刻返回。如果有一个worker进程试图取accept锁而没有取到，它至少要等accept_mutex_delay定义的时间间隔后才能再次试图取锁。 批量建立新连接语法： multi_accept[on|off];默认： multi_accept off;当事件模型通知有新连接时，尽可能地对本次调度中客户端发起的所有TCP请求都建立连接。 选择事件模型语法： use[kqueue|rtsig|epoll|/dev/poll|select|poll|eventport];默认： Nginx会自动使用最适合的事件模型。对于Linux操作系统来说，可供选择的事件驱动模型有poll、select、epoll三种。epoll当然是性能最高的一种，在9.6节会解释epoll为什么可以处理大并发连接。 每个worker的最大连接数语法： worker_connections number;定义每个worker进程可以同时处理的最大连接数。 2.4 用HTTP核心模块配置一个静态Web服务器静态Web服务器的主要功能由ngx_http_core_module模块（HTTP框架的主要成员）实现，当然，一个完整的静态Web服务器还有许多功能是由其他的HTTP模块实现的。本节主要讨论如何配置一个包含基本功能的静态Web服务器，文中会完整地说明ngx_http_core_module模块提供的配置项及变量的用法，但不会过多说明其他HTTP模块的配置项。在阅读完本节内容后，读者应当可以通过简单的查询相关模块（如ngx_http_gzip_filter_module、ngx_http_image_filter_module等）的配置项说明，方便地在nginx.conf配置文件中加入新的配置项，从而实现更多的Web服务器功能。除了2.3节提到的基本配置项外，一个典型的静态Web服务器还会包含多个server块和location块，例如： 123456789101112131415161718192021222324http &#123; gzip on; upstream &#123; ... &#125; ... server &#123; listen localhost:80; ... location /webstatic &#123; if ... &#123; ... &#125; root /opt/webresource; ... &#125; location ~* .(jpg|jpeg|png|jpe|gif)$ &#123; ... &#125; &#125; server &#123; ... &#125;&#125; 所有的HTTP配置项都必须直属于http块、server块、location块、upstream块或if块等（HTTP配置项自然必须全部在http{}块之内，这里的“直属于”是指配置项直接所属的大括号对应的配置块），同时，在描述每个配置项的功能时，会说明它可以在上述的哪个块中存在，因为有些配置项可以任意地出现在某一个块中，而有些配置项只能出现在特定的块中，在第4章介绍自定义配置项的读取时，相信读者就会体会到这种设计思路。Nginx为配置一个完整的静态Web服务器提供了非常多的功能，下面会把这些配置项分为以下8类进行详述：虚拟主机与请求的分发、文件路径的定义、内存及磁盘资源的分配、网络连接的设置、MIME类型的设置、对客户端请求的限制、文件操作的优化、对客户端请求的特殊处理。这种划分只是为了帮助大家从功能上理解这些配置项。在这之后会列出ngx_http_core_module模块提供的变量，以及简单说明它们的意义。 2.4.1 虚拟主机与请求的分发由于IP地址的数量有限，因此经常存在多个主机域名对应着同一个IP地址的情况，这时在nginx.conf中就可以按照server_name（对应用户请求中的主机域名）并通过server块来定义虚拟主机，每个server块就是一个虚拟主机，它只处理与之相对应的主机域名请求。这样，一台服务器上的Nginx就能以不同的方式处理访问不同主机域名的HTTP请求了。 监听端口语法： listen address:port[default(deprecated in 0.8.21)|default_server|[backlog=num|rcvbuf=size|sndbuf=size|accept_filter=filter|deferred|bind|ipv6only=[on|off]|ssl]];默认： listen 80;配置块： serverlisten参数决定Nginx服务如何监听端口。在listen后可以只加IP地址、端口或主机名，非常灵活，例如：12345listen 127.0.0.1:8000;listen 127.0.0.1; #注意：不加端口时，默认监听80端口listen 8000;listen *:8000;listen localhost:8000; 如果服务器使用IPv6地址，那么可以这样使用：123listen [::]:8000;listen [fe80::1];listen [:::a8c9:1234]:80; 在地址和端口后，还可以加上其他参数，例如：12listen 443 default_server ssl;listen 127.0.0.1 default_server accept_filter=dataready backlog=1024; 下面说明listen可用参数的意义。 default：将所在的server块作为整个Web服务的默认server块。如果没有设置这个参数，那么将会以在nginx.conf中找到的第一个server块作为默认server块。为什么需要默认虚拟主机呢？当一个请求无法匹配配置文件中的所有主机域名时，就会选用默认的虚拟主机（在11.3节介绍默认主机的使用）。 default_server：同上。 backlog&#x3D;num：表示TCP中backlog队列的大小。默认为–1，表示不予设置。在TCP建立三次握手过程中，进程还没有开始处理监听句柄，这时backlog队列将会放置这些新连接。可如果backlog队列已满，还有新的客户端试图通过三次握手建立TCP连接，这时客户端将会建立连接失败。 rcvbuf&#x3D;size：设置监听句柄的SO_RCVBUF参数。 sndbuf&#x3D;size：设置监听句柄的SO_SNDBUF参数。 accept_filter：设置accept过滤器，只对FreeBSD操作系统有用。 deferred：在设置该参数后，若用户发起建立连接请求，并且完成了TCP的三次握手，内核也不会为了这次的连接调度worker进程来处理，只有用户真的发送请求数据时（内核已经在网卡中收到请求数据包），内核才会唤醒worker进程处理这个连接。这个参数适用于大并发的情况下，它减轻了worker进程的负担。当请求数据来临时，worker进程才会开始处理这个连接。只有确认上面所说的应用场景符合自己的业务需求时，才可以使用deferred配置。 bind：绑定当前端口&#x2F;地址对，如127.0.0.1:8000。只有同时对一个端口监听多个地址时才会生效。 ssl：在当前监听的端口上建立的连接必须基于SSL协议。 主机名称语法： server_name name[...];默认： server_name&quot;&quot;;配置块： serverserver_name后可以跟多个主机名称，如server_name www.testweb.com 、download.testweb.com;。在开始处理一个HTTP请求时，Nginx会取出header头中的Host，与每个server中的server_name进行匹配，以此决定到底由哪一个server块来处理这个请求。有可能一个Host与多个server块中的server_name都匹配，这时就会根据匹配优先级来选择实际处理的server块。server_name与Host的匹配优先级如下： 首先选择所有字符串完全匹配的server_name，如www.testweb.com 。 其次选择通配符在前面的server_name，如*.testweb.com。 再次选择通配符在后面的server_name，如www.testweb.* 。 最后选择使用正则表达式才匹配的server_name，如~^.testweb.com$。实际上，这个规则正是7.7节中介绍的带通配符散列表的实现依据，同时，在10.4节也介绍了虚拟主机配置的管理。如果Host与所有的server_name都不匹配，这时将会按下列顺序选择处理的server块。 优先选择在listen配置项后加入[default|default_server]的server块。 找到匹配listen端口的第一个server块。如果server_name后跟着空字符串（如server_name””;），那么表示匹配没有Host这个HTTP头部的请求。 注意Nginx正是使用server_name配置项针对特定Host域名的请求提供不同的服务，以此实现虚拟主机功能。 server_names_hash_bucket_size语法： server_names_hash_bucket_size size;默认： server_names_hash_bucket_size 32|64|128;配置块： http、server、location为了提高快速寻找到相应server name的能力，Nginx使用散列表来存储server name。server_names_hash_bucket_size设置了每个散列桶占用的内存大小。 server_names_hash_max_size语法： server_names_hash_max_size size;默认： server_names_hash_max_size 512;配置块： http、server、locationserver_names_hash_max_size会影响散列表的冲突率。 server_names_hash_max_size越大，消耗的内存就越多，但散列key的冲突率则会降低，检索速度也更快。server_names_hash_max_size越小，消耗的内存就越小，但散列key的冲突率可能增高。 重定向主机名称的处理语法： server_name_in_redirect on|off;默认： server_name_in_redirect on;配置块： http、server或者location该配置需要配合server_name使用。在使用on打开时，表示在重定向请求时会使用server_name里配置的第一个主机名代替原先请求中的Host头部，而使用off关闭时，表示在重定向请求时使用请求本身的Host头部。 location语法： location[=|~|~*|^~|@]/uri/&#123;...&#125;配置块： serverlocation会尝试根据用户请求中的URI来匹配上面的&#x2F;uri表达式，如果可以匹配，就选择location{}块中的配置来处理用户请求。当然，匹配方式是多样的，下面介绍location的匹配规则。 &#x3D;表示把URI作为字符串，以便与参数中的uri做完全匹配。例如：1234location = / &#123; # 只有当用户请求是 /时，才会使用该location下的配置 ...&#125; ~表示匹配URI时是字母大小写敏感的。 ~*表示匹配URI时忽略字母大小写问题。 ^~表示匹配URI时只需要其前半部分与uri参数匹配即可。例如：1234location ^~ /images/ &#123; # 以/images/开始的请求都会匹配上 ...&#125; @表示仅用于Nginx服务内部请求之间的重定向，带有@的location不直接处理用户请求。当然，在uri参数里是可以用正则表达式的，例如：1234location ~* \\.(gif|jpg|jpeg)$ &#123; # 匹配以.gif、.jpg、.jpeg结尾的请求 ...&#125; 注意，location是有顺序的，当一个请求有可能匹配多个location时，实际上这个请求会被第一个location处理。在以上各种匹配方式中，都只能表达为“如果匹配…则…”。如果需要表达“如果不匹配…则…”，就很难直接做到。有一种解决方法是在最后一个location中使用&#x2F;作为参数，它会匹配所有的HTTP请求，这样就可以表示如果不能匹配前面的所有location，则由“&#x2F;”这个location处理。例如：1234location / &#123; # /可以匹配所有请求 ...&#125; 2.4.2 文件路径的定义下面介绍一下文件路径的定义配置项。 以root方式设置资源路径语法： root path;默认： root html;配置块： http、server、location、if例如，定义资源文件相对于HTTP请求的根目录。123location /download/ &#123; root /opt/web/html/;&#125; 在上面的配置中，如果有一个请求的URI是&#x2F;download&#x2F;index&#x2F;test.html，那么Web服务器将会返回服务器上&#x2F;opt&#x2F;web&#x2F;html&#x2F;download&#x2F;index&#x2F;test.html文件的内容。 以alias方式设置资源路径语法： alias path;配置块： locationalias也是用来设置文件资源路径的，它与root的不同点主要在于如何解读紧跟location后面的uri参数，这将会致使alias与root以不同的方式将用户请求映射到真正的磁盘文件上。例如，如果有一个请求的URI是&#x2F;conf&#x2F;nginx.conf，而用户实际想访问的文件在&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;nginx.conf，那么想要使用alias来进行设置的话，可以采用如下方式：123location /conf &#123; alias /usr/local/nginx/conf/;&#125; 如果用root设置，那么语句如下所示：123location /conf &#123; root /usr/local/nginx/;&#125; 使用alias时，在URI向实际文件路径的映射过程中，已经把location后配置的&#x2F;conf这部分字符串丢弃掉，因此，&#x2F;conf&#x2F;nginx.conf请求将根据alias path映射为path&#x2F;nginx.conf。root则不然，它会根据完整的URI请求来映射，因此，&#x2F;conf&#x2F;nginx.conf请求会根据root path映射为path&#x2F;conf&#x2F;nginx.conf。这也是root可以放置到http、server、location或if块中，而alias只能放置到location块中的原因。alias后面还可以添加正则表达式，例如：123location ~ ^/test/(\\w+)\\.(\\w+)$ &#123; alias /usr/local/nginx/$2/$1.$2;&#125; 这样，请求在访问&#x2F;test&#x2F;nginx.conf时，Nginx会返回&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;nginx.conf文件中的内容。 访问首页语法： index file...;默认： index index.html;配置块： http、server、location有时，访问站点时的URI是&#x2F;，这时一般是返回网站的首页，而这与root和alias都不同。这里用ngx_http_index_module模块提供的index配置实现。index后可以跟多个文件参数，Nginx将会按照顺序来访问这些文件，例如：1234location / &#123; root path; index /index.html /html/index.php /index.php;&#125; 接收到请求后，Nginx首先会尝试访问path&#x2F;index.php文件，如果可以访问，就直接返回文件内容结束请求，否则再试图返回path&#x2F;html&#x2F;index.php文件的内容，依此类推。 根据HTTP返回码重定向页面语法： error_page code[code...][=|=answer-code]uri|@named_location配置块： http、server、location、if当对于某个请求返回错误码时，如果匹配上了error_page中设置的code，则重定向到新的URI中。例如：1234error_page 404 /404.html;error_page 502 503 504 /50x.html;error_page 403 http://example.com/forbidden.html;error_page 404 = @fetch; 注意，虽然重定向了URI，但返回的HTTP错误码还是与原来的相同。用户可以通过“&#x3D;”来更改返回的错误码，例如：12error_page 404 =200 /empty.gif;error_page 404 =403 /forbidden.gif; 也可以不指定确切的返回错误码，而是由重定向后实际处理的真实结果来决定，这时，只要把“&#x3D;”后面的错误码去掉即可，例如：1error_page 404 = /empty.gif; 如果不想修改URI，只是想让这样的请求重定向到另一个location中进行处理，那么可以这样设置：123456location / ( error_page 404 @fallback;)location @fallback ( proxy_pass http://backend;) 这样，返回404的请求会被反向代理到http://backend 上游服务器中处理。 是否允许递归使用error_page语法： recursive_error_pages[on|off];默认： recursive_error_pages off;配置块： http、server、location确定是否允许递归地定义error_page。 try_files语法： try_files path1[path2]uri;配置块： server、locationtry_files后要跟若干路径，如path1 path2…，而且最后必须要有uri参数，意义如下：尝试按照顺序访问每一个path，如果可以有效地读取，就直接向用户返回这个path对应的文件结束请求，否则继续向下访问。如果所有的path都找不到有效的文件，就重定向到最后的参数uri上。因此，最后这个参数uri必须存在，而且它应该是可以有效重定向的。例如：1234try_files /system/maintenance.html $uri $uri/index.html $uri.html @other;location @other &#123; proxy_pass http://backend;&#125; 上面这段代码表示如果前面的路径，如&#x2F;system&#x2F;maintenance.html等，都找不到，就会反向代理到http://backend 服务上。还可以用指定错误码的方式与error_page配合使用，例如：123location / &#123;try_files $uri $uri/ /error.phpc=404 =404;&#125; 2.4.3 内存及磁盘资源的分配下面介绍处理请求时内存、磁盘资源分配的配置项。 HTTP包体只存储到磁盘文件中语法： client_body_in_file_only on|clean|off;默认： client_body_in_file_only off;配置块： http、server、location当值为非off时，用户请求中的HTTP包体一律存储到磁盘文件中，即使只有0字节也会存储为文件。当请求结束时，如果配置为on，则这个文件不会被删除（该配置一般用于调试、定位问题），但如果配置为clean，则会删除该文件。 HTTP包体尽量写入到一个内存buffer中语法： client_body_in_single_buffer on|off;默认： client_body_in_single_buffer off;配置块： http、server、location用户请求中的HTTP包体一律存储到内存buffer中。当然，如果HTTP包体的大小超过了下面client_body_buffer_size设置的值，包体还是会写入到磁盘文件中。 存储HTTP头部的内存buffer大小语法： client_header_buffer_size size;默认： client_header_buffer_size 1k;配置块： http、server上面配置项定义了正常情况下Nginx接收用户请求中HTTP header部分（包括HTTP行和HTTP头部）时分配的内存buffer大小。有时，请求中的HTTP header部分可能会超过这个大小，这时large_client_header_buffers定义的buffer将会生效。 存储超大HTTP头部的内存buffer大小语法： large_client_header_buffers number size;默认： large_client_header_buffers 48k;配置块： http、serverlarge_client_header_buffers定义了Nginx接收一个超大HTTP头部请求的buffer个数和每个buffer的大小。如果HTTP请求行（如GET&#x2F;index HTTP&#x2F;1.1）的大小超过上面的单个buffer，则返回”Request URI too large”(414)。请求中一般会有许多header，每一个header的大小也不能超过单个buffer的大小，否则会返回”Bad request”(400)。当然，请求行和请求头部的总和也不可以超过buffer个数*buffer大小。 存储HTTP包体的内存buffer大小语法： client_body_buffer_size size;默认： client_body_buffer_size 8k/16k;配置块： http、server、location上面配置项定义了Nginx接收HTTP包体的内存缓冲区大小。也就是说，HTTP包体会先接收到指定的这块缓存中，之后才决定是否写入磁盘。{ % note color:light 注意 如果用户请求中含有HTTP头部Content-Length，并且其标识的长度小于定义的buffer大小，那么Nginx会自动降低本次请求所使用的内存buffer，以降低内存消耗。 %} HTTP包体的临时存放目录语法： client_body_temp_path dir-path[level1[level2[level3]]]默认： client_body_temp_path client_body_temp;配置块： http、server、location上面配置项定义HTTP包体存放的临时目录。在接收HTTP包体时，如果包体的大小大于client_body_buffer_size，则会以一个递增的整数命名并存放到client_body_temp_path指定的目录中。后面跟着的level1、level2、level3，是为了防止一个目录下的文件数量太多，从而导致性能下降，因此使用了level参数，这样可以按照临时文件名最多再加三层目录。例如：1client_body_temp_path /opt/nginx/client_temp 1 2; 如果新上传的HTTP包体使用00000123456作为临时文件名，就会被存放在这个目录中。&#x2F;opt&#x2F;nginx&#x2F;client_temp&#x2F;6&#x2F;45&#x2F;00000123456 connection_pool_size语法： connection_pool_size size;默认： connection_pool_size 256;配置块： http、serverNginx对于每个建立成功的TCP连接会预先分配一个内存池，上面的size配置项将指定这个内存池的初始大小（即ngx_connection_t结构体中的pool内存池初始大小，9.8.1节将介绍这个内存池是何时分配的），用于减少内核对于小块内存的分配次数。需慎重设置，因为更大的size会使服务器消耗的内存增多，而更小的size则会引发更多的内存分配次数。 request_pool_size语法： request_pool_size size;默认： request_pool_size 4k;配置块： http、serverNginx开始处理HTTP请求时，将会为每个请求都分配一个内存池，size配置项将指定这个内存池的初始大小（即ngx_http_request_t结构体中的pool内存池初始大小，11.3节将介绍这个内存池是何时分配的），用于减少内核对于小块内存的分配次数。TCP连接关闭时会销毁connection_pool_size指定的连接内存池，HTTP请求结束时会销毁request_pool_size指定的HTTP请求内存池，但它们的创建、销毁时间并不一致，因为一个TCP连接可能被复用于多个HTTP请求。8.7节会详述内存池原理。 2.4.4 网络连接的设置下面介绍网络连接的设置配置项。 读取HTTP头部的超时时间语法： client_header_timeout time（默认单位：秒）;默认： client_header_timeout 60;配置块： http、server、location客户端与服务器建立连接后将开始接收HTTP头部，在这个过程中，如果在一个时间间隔（超时时间）内没有读取到客户端发来的字节，则认为超时，并向客户端返回408(“Request timed out”)响应。 读取HTTP包体的超时时间语法： client_body_timeout time（默认单位：秒）；默认： client_body_timeout 60;配置块： http、server、location此配置项与client_header_timeout相似，只是这个超时时间只在读取HTTP包体时才有效。 发送响应的超时时间语法： send_timeout time;默认： send_timeout 60;配置块： http、server、location这个超时时间是发送响应的超时时间，即Nginx服务器向客户端发送了数据包，但客户端一直没有去接收这个数据包。如果某个连接超过send_timeout定义的超时时间，那么Nginx将会关闭这个连接。 reset_timeout_connection语法： reset_timeout_connection on|off;默认： reset_timeout_connection off;配置块： http、server、location连接超时后将通过向客户端发送RST包来直接重置连接。这个选项打开后，Nginx会在某个连接超时后，不是使用正常情形下的四次握手关闭TCP连接，而是直接向用户发送RST重置包，不再等待用户的应答，直接释放Nginx服务器上关于这个套接字使用的所有缓存（如TCP滑动窗口）。相比正常的关闭方式，它使得服务器避免产生许多处于FIN_WAIT_1、FIN_WAIT_2、TIME_WAIT状态的TCP连接。注意，使用RST重置包关闭连接会带来一些问题，默认情况下不会开启。 lingering_close语法： lingering_close off|on|always;默认： lingering_close on;配置块： http、server、location该配置控制Nginx关闭用户连接的方式。always表示关闭用户连接前必须无条件地处理连接上所有用户发送的数据。off表示关闭连接时完全不管连接上是否已经有准备就绪的来自用户的数据。on是中间值，一般情况下在关闭连接前都会处理连接上的用户发送的数据，除了有些情况下在业务上认定这之后的数据是不必要的。 lingering_time语法： lingering_time time;默认： lingering_time 30s;配置块： http、server、locationlingering_close启用后，这个配置项对于上传大文件很有用。上文讲过，当用户请求的Content-Length大于max_client_body_size配置时，Nginx服务会立刻向用户发送413（Request entity too large）响应。但是，很多客户端可能不管413返回值，仍然持续不断地上传HTTP body，这时，经过了lingering_time设置的时间后，Nginx将不管用户是否仍在上传，都会把连接关闭掉。 lingering_timeout语法： lingering_timeout time;默认： lingering_timeout 5s;配置块： http、server、locationlingering_close生效后，在关闭连接前，会检测是否有用户发送的数据到达服务器，如果超过lingering_timeout时间后还没有数据可读，就直接关闭连接；否则，必须在读取完连接缓冲区上的数据并丢弃掉后才会关闭连接。 对某些浏览器禁用keepalive功能语法： keepalive_disable[msie6|safari|none]...默认： keepalive_disablemsie6 safari配置块： http、server、locationHTTP请求中的keepalive功能是为了让多个请求复用一个HTTP长连接，这个功能对服务器的性能提高是很有帮助的。但有些浏览器，如IE 6和Safari，它们对于使用keepalive功能的POST请求处理有功能性问题。因此，针对IE 6及其早期版本、Safari浏览器默认是禁用keepalive功能的。 keepalive超时时间语法： keepalive_timeout time（默认单位：秒）;默认： keepalive_timeout 75;配置块： http、server、location一个keepalive连接在闲置超过一定时间后（默认的是75秒），服务器和浏览器都会去关闭这个连接。当然，keepalive_timeout配置项是用来约束Nginx服务器的，Nginx也会按照规范把这个时间传给浏览器，但每个浏览器对待keepalive的策略有可能是不同的。 一个keepalive长连接上允许承载的请求最大数语法： keepalive_requests n;默认： keepalive_requests 100;配置块： http、server、location一个keepalive连接上默认最多只能发送100个请求。 tcp_nodelay语法： tcp_nodelay on|off;默认： tcp_nodelay on;配置块： http、server、location确定对keepalive连接是否使用TCP_NODELAY选项。 tcp_nopush语法： tcp_nopush on|off;默认： tcp_nopush off;配置块： http、server、location在打开sendfile选项时，确定是否开启FreeBSD系统上的TCP_NOPUSH或Linux系统上的TCP_CORK功能。打开tcp_nopush后，将会在发送响应时把整个响应包头放到一个TCP包中发送。 2.4.5 MIME类型的设置下面是MIME类型的设置配置项。 MIME type与文件扩展的映射语法： type&#123;...&#125;;配置块： http、server、location定义MIME type到文件扩展名的映射。多个扩展名可以映射到同一个MIME type。例如： 123456types &#123; text/html html; text/html conf; image/gif gif; image/jpeg jpg;&#125; 默认MIME type语法： default_type MIME-type;默认： default_type text/plain;配置块： http、server、location当找不到相应的MIME type与文件扩展名之间的映射时，使用默认的MIME type作为HTTP header中的Content-Type。 types_hash_bucket_size语法： types_hash_bucket_size size;默认： types_hash_bucket_size 32|64|128;配置块： http、server、location为了快速寻找到相应MIME type，Nginx使用散列表来存储MIMEtype与文件扩展名。types_hash_bucket_size设置了每个散列桶占用的内存大小。 types_hash_max_size语法： types_hash_max_size size;默认： types_hash_max_size 1024;配置块： http、server、locationtypes_hash_max_size影响散列表的冲突率。types_hash_max_size越大，就会消耗更多的内存，但散列key的冲突率会降低，检索速度就更快。types_hash_max_size越小，消耗的内存就越小，但散列key的冲突率可能上升。 2.4.6 对客户端请求的限制下面介绍对客户端请求的限制的配置项。 按HTTP方法名限制用户请求语法： limit_except method...&#123;...&#125;配置块： locationNginx通过limit_except后面指定的方法名来限制用户请求。方法名可取值包括：GET、HEAD、POST、PUT、DELETE、MKCOL、COPY、MOVE、OPTIONS、PROPFIND、PROPPATCH、LOCK、UNLOCK或者PATCH。例如：1234limit_except GET &#123; allow 192.168.1.0/32; deny all;&#125; 注意，允许GET方法就意味着也允许HEAD方法。因此，上面这段代码表示的是禁止GET方法和HEAD方法，但其他HTTP方法是允许的。 HTTP请求包体的最大值语法： client_max_body_size size;默认： client_max_body_size 1m;配置块： http、server、location浏览器在发送含有较大HTTP包体的请求时，其头部会有一个Content-Length字段，client_max_body_size是用来限制Content-Length所示值的大小的。因此，这个限制包体的配置非常有用处，因为不用等Nginx接收完所有的HTTP包体——这有可能消耗很长时间——就可以告诉用户请求过大不被接受。例如，用户试图上传一个10GB的文件，Nginx在收完包头后，发现Content-Length超过client_max_body_size定义的值，就直接发送413(“Request Entity Too Large”)响应给客户端。 对请求的限速语法： limit_rate speed;默认： limit_rate 0;配置块： http、server、location、if此配置是对客户端请求限制每秒传输的字节数。speed可以使用2.2.4节中提到的多种单位，默认参数为0，表示不限速。针对不同的客户端，可以用$limit_rate参数执行不同的限速策略。例如：12345server &#123; if ($slow) &#123; set $limit_rate 4k; &#125;&#125; limit_rate_after语法： limit_rate_after time;默认： limit_rate_after 1m;配置块： http、server、location、if此配置表示Nginx向客户端发送的响应长度超过limit_rate_after后才开始限速。例如：12limit_rate_after 1m;limit_rate 100k; 11.9.2节将从源码上介绍limit_rate_after与limit_rate的区别，以及HTTP框架是如何使用它们来限制发送响应速度的。 2.4.7 文件操作的优化下面介绍文件操作的优化配置项。 sendfile系统调用语法： sendfile on|off;默认： sendfile off;配置块： http、server、location可以启用Linux上的sendfile系统调用来发送文件，它减少了内核态与用户态之间的两次内存复制，这样就会从磁盘中读取文件后直接在内核态发送到网卡设备，提高了发送文件的效率。 AIO系统调用语法： aio on|off;默认： aio off;配置块： http、server、location此配置项表示是否在FreeBSD或Linux系统上启用内核级别的异步文件I&#x2F;O功能。注意，它与sendfile功能是互斥的。 directio语法： directio size|off;默认： directio off;配置块： http、server、location此配置项在FreeBSD和Linux系统上使用O_DIRECT选项去读取文件，缓冲区大小为size，通常对大文件的读取速度有优化作用。注意，它与sendfile功能是互斥的。 directio_alignment语法： directio_alignment size;默认： directio_alignment 512;配置块： http、server、location它与directio配合使用，指定以directio方式读取文件时的对齐方式。一般情况下，512B已经足够了，但针对一些高性能文件系统，如Linux下的XFS文件系统，可能需要设置到4KB作为对齐方式。 打开文件缓存语法： open_file_cache max=N[inactive=time]|off;默认： open_file_cache off;配置块： http、server、location文件缓存会在内存中存储以下3种信息： 文件句柄、文件大小和上次修改时间。 已经打开过的目录结构。 没有找到的或者没有权限操作的文件信息。这样，通过读取缓存就减少了对磁盘的操作。该配置项后面跟3种参数。 max：表示在内存中存储元素的最大个数。当达到最大限制数量后，将采用LRU（Least Recently Used）算法从缓存中淘汰最近最少使用的元素。 inactive：表示在inactive指定的时间段内没有被访问过的元素将会被淘汰。默认时间为60秒。 off：关闭缓存功能。例如：1open_file_cache max=1000 inactive=20s; 是否缓存打开文件错误的信息语法： open_file_cache_errors on|off;默认： open_file_cache_errors off;配置块： http、server、location此配置项表示是否在文件缓存中缓存打开文件时出现的找不到路径、没有权限等错误信息。 不被淘汰的最小访问次数语法： open_file_cache_min_uses number;默认： open_file_cache_min_uses 1;配置块： http、server、location它与open_file_cache中的inactive参数配合使用。如果在inactive指定的时间段内，访问次数超过了open_file_cache_min_uses指定的最小次数，那么将不会被淘汰出缓存。 检验缓存中元素有效性的频率语法： open_file_cache_valid time;默认： open_file_cache_valid 60s;配置块： http、server、location默认为每60秒检查一次缓存中的元素是否仍有效。 2.4.8 对客户端请求的特殊处理下面介绍对客户端请求的特殊处理的配置项。 忽略不合法的HTTP头部语法： ignore_invalid_headers on|off;默认： ignore_invalid_headers on;配置块： http、server如果将其设置为off，那么当出现不合法的HTTP头部时，Nginx会拒绝服务，并直接向用户发送400（Bad Request）错误。如果将其设置为on，则会忽略此HTTP头部。 HTTP头部是否允许下划线语法： underscores_in_headers on|off;默认： underscores_in_headers off;配置块： http、server默认为off，表示HTTP头部的名称中不允许带“_”（下划线）。 对If-Modified-Since头部的处理策略语法： if_modified_since[off|exact|before];默认： if_modified_since exact;配置块： http、server、location出于性能考虑，Web浏览器一般会在客户端本地缓存一些文件，并存储当时获取的时间。这样，下次向Web服务器获取缓存过的资源时，就可以用If-Modified-Since头部把上次获取的时间捎带上，而if_modified_since将根据后面的参数决定如何处理If-Modified-Since头部。相关参数说明如下。 off：表示忽略用户请求中的If-Modified-Since头部。这时，如果获取一个文件，那么会正常地返回文件内容。HTTP响应码通常是200。 exact：将If-Modified-Since头部包含的时间与将要返回的文件上次修改的时间做精确比较，如果没有匹配上，则返回200和文件的实际内容，如果匹配上，则表示浏览器缓存的文件内容已经是最新的了，没有必要再返回文件从而浪费时间与带宽了，这时会返回304 Not Modified，浏览器收到后会直接读取自己的本地缓存。 before：是比exact更宽松的比较。只要文件的上次修改时间等于或者早于用户请求中的If-Modified-Since头部的时间，就会向客户端返回304 Not Modified。 文件未找到时是否记录到error日志语法： log_not_found on|off;默认： log_not_found on;配置块： http、server、location此配置项表示当处理用户请求且需要访问文件时，如果没有找到文件，是否将错误日志记录到error.log文件中。这仅用于定位问题。 merge_slashes语法： merge_slashes on|off;默认： merge_slashes on;配置块： http、server、location此配置项表示是否合并相邻的“&#x2F;”，例如，&#x2F;&#x2F;test&#x2F;&#x2F;&#x2F;a.txt，在配置为on时，会将其匹配为location&#x2F;test&#x2F;a.txt；如果配置为off，则不会匹配，URI将仍然是&#x2F;&#x2F;test&#x2F;&#x2F;&#x2F;a.txt。 DNS解析地址语法： resolver address...;配置块： http、server、location设置DNS名字解析服务器的地址，例如：1resolver 127.0.0.1 192.0.2.1; DNS解析的超时时间语法： resolver_timeout time;默认： resolver_timeout 30s;配置块： http、server、location此配置项表示DNS解析的超时时间。 返回错误页面时是否在Server中注明Nginx版本语法： server_tokens on|off;默认： server_tokens on;配置块： http、server、location表示处理请求出错时是否在响应的Server头部中标明Nginx版本，这是为了方便定位问题。 2.4.9 ngx_http_core_module模块提供的变量在记录access_log访问日志文件时，可以使用ngx_http_core_module模块处理请求时所产生的丰富的变量，当然，这些变量还可以用于其他HTTP模块。例如，当URI中的某个参数满足设定的条件时，有些HTTP模块的配置项可以使用类似$arg_PARAMETER这样的变量。又如，若想把每个请求中的限速信息记录到access日志文件中，则可以使用$limit_rate变量。表2-1列出了ngx_http_core_module模块提供的这些变量。 表2-1 ngx_http_core_module模块提供的变量 2.5 用HTTP proxy module配置一个反向代理服务器反向代理（reverse proxy）方式是指用代理服务器来接受Internet上的连接请求，然后将请求转发给内部网络中的上游服务器，并将从上游服务器上得到的结果返回给Internet上请求连接的客户端，此时代理服务器对外的表现就是一个Web服务器。充当反向代理服务器也是Nginx的一种常见用法（反向代理服务器必须能够处理大量并发请求），本节将介绍Nginx作为HTTP反向代理服务器的基本用法。由于Nginx具有“强悍”的高并发高负载能力，因此一般会作为前端的服务器直接向客户端提供静态文件服务。但也有一些复杂、多变的业务不适合放到Nginx服务器上，这时会用Apache、Tomcat等服务器来处理。于是，Nginx通常会被配置为既是静态Web服务器也是反向代理服务器（如图2-3所示），不适合Nginx处理的请求就会直接转发到上游服务器中处理。 图2-3 作为静态Web服务器与反向代理服务器的Nginx 与Squid等其他反向代理服务器相比，Nginx的反向代理功能有自己的特点，如图2-4所示。当客户端发来HTTP请求时，Nginx并不会立刻转发到上游服务器，而是先把用户的请求（包括HTTP包体）完整地接收到Nginx所在服务器的硬盘或者内存中，然后再向上游服务器发起连接，把缓存的客户端请求转发到上游服务器。而Squid等代理服务器则采用一边接收客户端请求，一边转发到上游服务器的方式。Nginx的这种工作方式有什么优缺点呢？很明显，缺点是延长了一个请求的处理时间，并增加了用于缓存请求内容的内存和磁盘空间。而优点则是降低了上游服务器的负载，尽量把压力放在Nginx服务器上。 图2-4 Nginx作为反向代理服务器时转发请求的流程 Nginx的这种工作方式为什么会降低上游服务器的负载呢？通常，客户端与代理服务器之间的网络环境会比较复杂，多半是“走”公网，网速平均下来可能较慢，因此，一个请求可能要持续很久才能完成。而代理服务器与上游服务器之间一般是“走”内网，或者有专线连接，传输速度较快。Squid等反向代理服务器在与客户端建立连接且还没有开始接收HTTP包体时，就已经向上游服务器建立了连接。例如，某个请求要上传一个1GB的文件，那么每次Squid在收到一个TCP分包（如2KB）时，就会即时地向上游服务器转发。在接收客户端完整HTTP包体的漫长过程中，上游服务器始终要维持这个连接，这直接对上游服务器的并发处理能力提出了挑战。Nginx则不然，它在接收到完整的客户端请求（如1GB的文件）后，才会与上游服务器建立连接转发请求，由于是内网，所以这个转发过程会执行得很快。这样，一个客户端请求占用上游服务器的连接时间就会非常短，也就是说，Nginx的这种反向代理方案主要是为了降低上游服务器的并发压力。Nginx将上游服务器的响应转发到客户端有许多种方法，第12章将介绍其中常见的两种方式。 2.5.1 负载均衡的基本配置作为代理服务器，一般都需要向上游服务器的集群转发请求。这里的负载均衡是指选择一种策略，尽量把请求平均地分布到每一台上游服务器上。下面介绍负载均衡的配置项。 upstream块语法： upstream name&#123;...&#125;配置块： httpupstream块定义了一个上游服务器的集群，便于反向代理中的proxy_pass使用。例如：12345678910upstream backend &#123; server backend1.example.com; server backend2.example.com; server backend3.example.com;&#125;server &#123; location / &#123; proxy_pass http://backend; &#125;&#125; server语法： server name[parameters];配置块： upstreamserver配置项指定了一台上游服务器的名字，这个名字可以是域名、IP地址端口、UNIX句柄等，在其后还可以跟下列参数。 weight&#x3D;number：设置向这台上游服务器转发的权重，默认为1。 max_fails&#x3D;number：该选项与fail_timeout配合使用，指在fail_timeout时间段内，如果向当前的上游服务器转发失败次数超过number，则认为在当前的fail_timeout时间段内这台上游服务器不可用。max_fails默认为1，如果设置为0，则表示不检查失败次数。 fail_timeout&#x3D;time：fail_timeout表示该时间段内转发失败多少次后就认为上游服务器暂时不可用，用于优化反向代理功能。它与向上游服务器建立连接的超时时间、读取上游服务器的响应超时时间等完全无关。fail_timeout默认为10秒。 down：表示所在的上游服务器永久下线，只在使用ip_hash配置项时才有用。 backup：在使用ip_hash配置项时它是无效的。它表示所在的上游服务器只是备份服务器，只有在所有的非备份上游服务器都失效后，才会向所在的上游服务器转发请求。例如：12345upstream backend &#123; server backend1.example.com weight=5; server 127.0.0.1:8080 max_fails=3 fail_timeout=30s; server unix:/tmp/backend3;&#125; ip_hash语法： ip_hash; 配置块： upstream在有些场景下，我们可能会希望来自某一个用户的请求始终落到固定的一台上游服务器中。例如，假设上游服务器会缓存一些信息，如果同一个用户的请求任意地转发到集群中的任一台上游服务器中，那么每一台上游服务器都有可能会缓存同一份信息，这既会造成资源的浪费，也会难以有效地管理缓存信息。ip_hash就是用以解决上述问题的，它首先根据客户端的IP地址计算出一个key，将key按照upstream集群里的上游服务器数量进行取模，然后以取模后的结果把请求转发到相应的上游服务器中。这样就确保了同一个客户端的请求只会转发到指定的上游服务器中。ip_hash与weight（权重）配置不可同时使用。如果upstream集群中有一台上游服务器暂时不可用，不能直接删除该配置，而是要down参数标识，确保转发策略的一贯性。例如：1234567upstream backend &#123; ip_hash; server backend1.example.com; server backend2.example.com; server backend3.example.com down; server backend4.example.com;&#125; 记录日志时支持的变量如果需要将负载均衡时的一些信息记录到access_log日志中，那么在定义日志格式时可以使用负载均衡功能提供的变量，见表2-2。表2-2 访问上游服务器时可以使用的变量 例如，可以在定义access_log访问日志格式时使用表2-2中的变量。12345log_format timing &#x27;$remote_addr - $remote_user [$time_local] $request &#x27; &#x27;upstream_response_time $upstream_response_time &#x27; &#x27;msec $msec request_time $request_time&#x27;;log_format up_head &#x27;$remote_addr - $remote_user [$time_local] $request &#x27; &#x27;upstream_http_content_type $upstream_http_content_type&#x27;; 2.5.2 反向代理的基本配置下面介绍反向代理的基本配置项。 proxy_pass语法： proxy_pass URL;配置块： location、if此配置项将当前请求反向代理到URL参数指定的服务器上，URL可以是主机名或IP地址加端口的形式，例如：1proxy_pass http://localhost:8000/uri/; 也可以是UNIX句柄：1proxy_pass http://unix:/path/to/backend.socket:/uri/ ; 还可以如上节负载均衡中所示，直接使用upstream块，例如：12345678upstream backend &#123; ... &#125;server &#123; location / &#123; proxy_pass http://backend; &#125;&#125; 用户可以把HTTP转换成更安全的HTTPS，例如：1proxy_pass https://192.168.0.1; 默认情况下反向代理是不会转发请求中的Host头部的。如果需要转发，那么必须加上配置：1proxy_set_header Host $host; proxy_method语法： proxy_method method;配置块： http、server、location此配置项表示转发时的协议方法名。例如设置为：1proxy_method POST; 那么客户端发来的GET请求在转发时方法名也会改为POST。 proxy_hide_header语法： proxy_hide_header the_header;配置块： http、server、locationNginx会将上游服务器的响应转发给客户端，但默认不会转发以下HTTP头部字段：Date、Server、X-Pad和X-Accel-*。使用proxy_hide_header后可以任意地指定哪些HTTP头部字段不能被转发。例如：12proxy_hide_header Cache-Control;proxy_hide_header MicrosoftOfficeWebServer; proxy_pass_header语法： proxy_pass_header the_header;配置块： http、server、location与proxy_hide_header功能相反，proxy_pass_header会将原来禁止转发的header设置为允许转发。例如：1proxy_pass_header X-Accel-Redirect; proxy_pass_request_body语法： proxy_pass_request_body on|off;默认： proxy_pass_request_body on;配置块： http、server、location作用为确定是否向上游服务器发送HTTP包体部分。 proxy_pass_request_headers语法： proxy_pass_request_headers on|off;默认： proxy_pass_request_headers on;配置块： http、server、location作用为确定是否转发HTTP头部。 proxy_redirect语法： proxy_redirect[default|off|redirect replacement];默认： proxy_redirect default;配置块： http、server、location当上游服务器返回的响应是重定向或刷新请求（如HTTP响应码是301或者302）时，proxy_redirect可以重设HTTP头部的location或refresh字段。例如，如果上游服务器发出的响应是302重定向请求，location字段的URI是http://localhost:8000/two/some/uri/ ，那么在下面的配置情况下，实际转发给客户端的location是http://frontend/one/some/uri/ 。12proxy_redirect http://localhost:8000/two/http://frontend/one/; 这里还可以使用ngx-http-core-module提供的变量来设置新的location字段。例如：12proxy_redirect http://localhost:8000/http://$host:$server_port/; 也可以省略replacement参数中的主机名部分，这时会用虚拟主机名称来填充。例如：1proxy_redirect http://localhost:8000/two//one/; 使用off参数时，将使location或者refresh字段维持不变。例如：1proxy_redirect off; 使用默认的default参数时，会按照proxy_pass配置项和所属的location配置项重组发往客户端的location头部。例如，下面两种配置效果是一样的：12345678location /one/ &#123; proxy_pass http://upstream:port/two/; proxy_redirect default;&#125;location /one/ &#123; proxy_pass http://upstream:port/two/; proxy_redirect http://upstream:port/two//one/;&#125; proxy_next_upstream语法： proxy_next_upstream[error|timeout|invalid_header|http_500|http_502|http_503|http_504|http_404|off];默认： proxy_next_upstream error timeout;配置块： http、server、location此配置项表示当向一台上游服务器转发请求出现错误时，继续换一台上游服务器处理这个请求。前面已经说过，上游服务器一旦开始发送应答，Nginx反向代理服务器会立刻把应答包转发给客户端。因此，一旦Nginx开始向客户端发送响应包，之后的过程中若出现错误也是不允许换下一台上游服务器继续处理的。这很好理解，这样才可以更好地保证客户端只收到来自一个上游服务器的应答。 proxy_next_upstream的参数用来说明在哪些情况下会继续选择下一台上游服务器转发请求。 error：当向上游服务器发起连接、发送请求、读取响应时出错。 timeout：发送请求或读取响应时发生超时。 invalid_header：上游服务器发送的响应是不合法的。 http_500：上游服务器返回的HTTP响应码是500。 http_502：上游服务器返回的HTTP响应码是502。 http_503：上游服务器返回的HTTP响应码是503。 http_504：上游服务器返回的HTTP响应码是504。 http_404：上游服务器返回的HTTP响应码是404。 off：关闭proxy_next_upstream功能—出错就选择另一台上游服务器再次转发。 Nginx的反向代理模块还提供了很多种配置，如设置连接的超时时间、临时文件如何存储，以及最重要的如何缓存上游服务器响应等功能。这些配置可以通过阅读ngx_http_proxy_module模块的说明了解，只有深入地理解，才能实现一个高性能的反向代理服务器。本节只是介绍反向代理服务器的基本功能，在第12章中我们将会深入地探索upstream机制，到那时，读者也许会发现ngx_http_proxy_module模块只是使用upstream机制实现了反向代理功能而已。 2.6 小结Nginx由少量的核心框架代码和许多模块组成，每个模块都有它独特的功能。因此，读者可以通过查看每个模块实现了什么功能，来了解Nginx可以帮我们做些什么。Nginx的Wiki网站（http://wiki.nginx.org/Modules ）上列出了官方提供的所有模块及配置项，仔细观察就会发现，这些配置项的语法与本章的内容都是很相近的，读者只需要弄清楚模块说明中每个配置项的意义即可。另外，网页http://wiki.nginx.org/3rdPartyModules 中列出了Wiki上已知的几十个第三方模块，同时读者还可以从搜索引擎上搜索到更多的第三方模块。了解每个模块的配置项用法，并在Nginx中使用这些模块，可以让Nginx做到更多。随着对本书的学习，读者会对Nginx模块的设计思路有深入的了解，也会渐渐熟悉如何编写一个模块。如果某个模块的实现与你的想法有出入，可以更改这个模块的源码，实现你期望的业务功能。如果所有的模块都没有你想要的功能，不妨自己重写一个定制的模块，也可以申请发布到Nginx网站上供大家分享。"}]